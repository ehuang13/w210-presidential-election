{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"../../merged_dataset_ellie.csv\")\n",
    "data = pd.read_csv(\"../../data/combined_jun22_train.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>YEAR_FIPS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>COUNTY_FIPS</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>REP_CANDIDATE</th>\n",
       "      <th>DEM_CANDIDATE</th>\n",
       "      <th>REP_VOTES</th>\n",
       "      <th>DEM_VOTES</th>\n",
       "      <th>COUNTY_TOTALVOTES</th>\n",
       "      <th>WINNING_CANDIDATE</th>\n",
       "      <th>WINNING_PARTY</th>\n",
       "      <th>WINNING_PARTY_BINARY</th>\n",
       "      <th>HOUSE_WINNING_BINARY</th>\n",
       "      <th>SENATE_WINNING_BINARY</th>\n",
       "      <th>UNEMPLOYMENT_RATE</th>\n",
       "      <th>AVG_WAGE_SALARY</th>\n",
       "      <th>AA_FEMALE</th>\n",
       "      <th>AA_MALE</th>\n",
       "      <th>BA_FEMALE</th>\n",
       "      <th>BA_MALE</th>\n",
       "      <th>H_FEMALE</th>\n",
       "      <th>H_MALE</th>\n",
       "      <th>IA_FEMALE</th>\n",
       "      <th>IA_MALE</th>\n",
       "      <th>NA_FEMALE</th>\n",
       "      <th>NA_MALE</th>\n",
       "      <th>TOT_FEMALE</th>\n",
       "      <th>TOT_MALE</th>\n",
       "      <th>TOT_POP</th>\n",
       "      <th>WA_FEMALE</th>\n",
       "      <th>WA_MALE</th>\n",
       "      <th>TOT_POP_LESS19</th>\n",
       "      <th>TOT_MALE_LESS19</th>\n",
       "      <th>TOT_FEMALE_LESS19</th>\n",
       "      <th>TOT_POP_20to39</th>\n",
       "      <th>TOT_MALE_20to39</th>\n",
       "      <th>TOT_FEMALE_20to39</th>\n",
       "      <th>TOT_POP_40to59</th>\n",
       "      <th>TOT_MALE_40to59</th>\n",
       "      <th>TOT_FEMALE_40to59</th>\n",
       "      <th>TOT_POP_Above60</th>\n",
       "      <th>TOT_MALE_Above60</th>\n",
       "      <th>TOT_FEMALE_Above60</th>\n",
       "      <th>AA_FEMALE%</th>\n",
       "      <th>AA_MALE%</th>\n",
       "      <th>BA_FEMALE%</th>\n",
       "      <th>BA_MALE%</th>\n",
       "      <th>H_FEMALE%</th>\n",
       "      <th>H_MALE%</th>\n",
       "      <th>IA_FEMALE%</th>\n",
       "      <th>IA_MALE%</th>\n",
       "      <th>NA_FEMALE%</th>\n",
       "      <th>NA_MALE%</th>\n",
       "      <th>WA_FEMALE%</th>\n",
       "      <th>WA_MALE%</th>\n",
       "      <th>TOT_FEMALE%</th>\n",
       "      <th>TOT_MALE%</th>\n",
       "      <th>TOT_POP_LESS19%</th>\n",
       "      <th>TOT_POP_20to39%</th>\n",
       "      <th>TOT_POP_40to59%</th>\n",
       "      <th>TOT_POP_Above60%</th>\n",
       "      <th>MARGIN_VICTORY</th>\n",
       "      <th>TRAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>4235</td>\n",
       "      <td>4606</td>\n",
       "      <td>201622071</td>\n",
       "      <td>2016</td>\n",
       "      <td>22</td>\n",
       "      <td>71</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Orleans Parish</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>24292.0</td>\n",
       "      <td>133996.0</td>\n",
       "      <td>165812.0</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>151464.0</td>\n",
       "      <td>5614</td>\n",
       "      <td>5534</td>\n",
       "      <td>126132</td>\n",
       "      <td>106710</td>\n",
       "      <td>9419</td>\n",
       "      <td>11258</td>\n",
       "      <td>590</td>\n",
       "      <td>738</td>\n",
       "      <td>109</td>\n",
       "      <td>149</td>\n",
       "      <td>200441</td>\n",
       "      <td>183489</td>\n",
       "      <td>383930</td>\n",
       "      <td>65018</td>\n",
       "      <td>67765</td>\n",
       "      <td>88156</td>\n",
       "      <td>44430</td>\n",
       "      <td>43726</td>\n",
       "      <td>125685</td>\n",
       "      <td>60041</td>\n",
       "      <td>65644</td>\n",
       "      <td>99227</td>\n",
       "      <td>47874</td>\n",
       "      <td>51353</td>\n",
       "      <td>70862</td>\n",
       "      <td>31144</td>\n",
       "      <td>39718</td>\n",
       "      <td>0.014622</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>0.328529</td>\n",
       "      <td>0.277941</td>\n",
       "      <td>0.024533</td>\n",
       "      <td>0.029323</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.169349</td>\n",
       "      <td>0.176504</td>\n",
       "      <td>0.522077</td>\n",
       "      <td>0.477923</td>\n",
       "      <td>0.229615</td>\n",
       "      <td>0.327364</td>\n",
       "      <td>0.258451</td>\n",
       "      <td>0.184570</td>\n",
       "      <td>0.661617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14679</th>\n",
       "      <td>14679</td>\n",
       "      <td>17964</td>\n",
       "      <td>200847059</td>\n",
       "      <td>2008</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Greene County</td>\n",
       "      <td>John McCain</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>17151.0</td>\n",
       "      <td>7110.0</td>\n",
       "      <td>24670.0</td>\n",
       "      <td>John McCain</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127</td>\n",
       "      <td>112</td>\n",
       "      <td>679</td>\n",
       "      <td>719</td>\n",
       "      <td>627</td>\n",
       "      <td>863</td>\n",
       "      <td>106</td>\n",
       "      <td>76</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>34562</td>\n",
       "      <td>33278</td>\n",
       "      <td>67840</td>\n",
       "      <td>33320</td>\n",
       "      <td>32058</td>\n",
       "      <td>16483</td>\n",
       "      <td>8543</td>\n",
       "      <td>7940</td>\n",
       "      <td>16045</td>\n",
       "      <td>8142</td>\n",
       "      <td>7903</td>\n",
       "      <td>19917</td>\n",
       "      <td>9716</td>\n",
       "      <td>10201</td>\n",
       "      <td>15395</td>\n",
       "      <td>6877</td>\n",
       "      <td>8518</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.010598</td>\n",
       "      <td>0.009242</td>\n",
       "      <td>0.012721</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.491156</td>\n",
       "      <td>0.472553</td>\n",
       "      <td>0.509463</td>\n",
       "      <td>0.490537</td>\n",
       "      <td>0.242969</td>\n",
       "      <td>0.236512</td>\n",
       "      <td>0.293588</td>\n",
       "      <td>0.226931</td>\n",
       "      <td>-0.407013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>2503</td>\n",
       "      <td>2872</td>\n",
       "      <td>201241065</td>\n",
       "      <td>2012</td>\n",
       "      <td>41</td>\n",
       "      <td>65</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Wasco County</td>\n",
       "      <td>Mitt Romney</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>5229.0</td>\n",
       "      <td>5211.0</td>\n",
       "      <td>10873.0</td>\n",
       "      <td>Mitt Romney</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>36244.0</td>\n",
       "      <td>121</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "      <td>68</td>\n",
       "      <td>1782</td>\n",
       "      <td>2016</td>\n",
       "      <td>589</td>\n",
       "      <td>617</td>\n",
       "      <td>86</td>\n",
       "      <td>78</td>\n",
       "      <td>12748</td>\n",
       "      <td>12537</td>\n",
       "      <td>25285</td>\n",
       "      <td>11656</td>\n",
       "      <td>11413</td>\n",
       "      <td>6483</td>\n",
       "      <td>3325</td>\n",
       "      <td>3158</td>\n",
       "      <td>5638</td>\n",
       "      <td>2856</td>\n",
       "      <td>2782</td>\n",
       "      <td>6853</td>\n",
       "      <td>3391</td>\n",
       "      <td>3462</td>\n",
       "      <td>6311</td>\n",
       "      <td>2965</td>\n",
       "      <td>3346</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.070477</td>\n",
       "      <td>0.079731</td>\n",
       "      <td>0.023294</td>\n",
       "      <td>0.024402</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.460985</td>\n",
       "      <td>0.451374</td>\n",
       "      <td>0.504172</td>\n",
       "      <td>0.495828</td>\n",
       "      <td>0.256397</td>\n",
       "      <td>0.222978</td>\n",
       "      <td>0.271030</td>\n",
       "      <td>0.249595</td>\n",
       "      <td>-0.001655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>6700</td>\n",
       "      <td>9899</td>\n",
       "      <td>200018051</td>\n",
       "      <td>2000</td>\n",
       "      <td>18</td>\n",
       "      <td>51</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Gibson County</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>7734.0</td>\n",
       "      <td>5802.0</td>\n",
       "      <td>13772.0</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>59266.0</td>\n",
       "      <td>53</td>\n",
       "      <td>118</td>\n",
       "      <td>303</td>\n",
       "      <td>326</td>\n",
       "      <td>113</td>\n",
       "      <td>116</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16584</td>\n",
       "      <td>15889</td>\n",
       "      <td>32473</td>\n",
       "      <td>16087</td>\n",
       "      <td>15325</td>\n",
       "      <td>8942</td>\n",
       "      <td>4576</td>\n",
       "      <td>4366</td>\n",
       "      <td>8296</td>\n",
       "      <td>4249</td>\n",
       "      <td>4047</td>\n",
       "      <td>8718</td>\n",
       "      <td>4357</td>\n",
       "      <td>4361</td>\n",
       "      <td>6517</td>\n",
       "      <td>2707</td>\n",
       "      <td>3810</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>0.010039</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.471931</td>\n",
       "      <td>0.510701</td>\n",
       "      <td>0.489299</td>\n",
       "      <td>0.275367</td>\n",
       "      <td>0.255474</td>\n",
       "      <td>0.268469</td>\n",
       "      <td>0.200690</td>\n",
       "      <td>-0.140285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5484</th>\n",
       "      <td>5484</td>\n",
       "      <td>5855</td>\n",
       "      <td>201646073</td>\n",
       "      <td>2016</td>\n",
       "      <td>46</td>\n",
       "      <td>73</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Jerauld County</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>648.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>34777.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1031</td>\n",
       "      <td>1010</td>\n",
       "      <td>2041</td>\n",
       "      <td>1007</td>\n",
       "      <td>993</td>\n",
       "      <td>505</td>\n",
       "      <td>274</td>\n",
       "      <td>231</td>\n",
       "      <td>370</td>\n",
       "      <td>192</td>\n",
       "      <td>178</td>\n",
       "      <td>466</td>\n",
       "      <td>248</td>\n",
       "      <td>218</td>\n",
       "      <td>700</td>\n",
       "      <td>296</td>\n",
       "      <td>404</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>0.024008</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493386</td>\n",
       "      <td>0.486526</td>\n",
       "      <td>0.505145</td>\n",
       "      <td>0.494855</td>\n",
       "      <td>0.247428</td>\n",
       "      <td>0.181284</td>\n",
       "      <td>0.228319</td>\n",
       "      <td>0.342969</td>\n",
       "      <td>-0.397104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>951</td>\n",
       "      <td>201211001</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>Mitt Romney</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>21381.0</td>\n",
       "      <td>267070.0</td>\n",
       "      <td>293764.0</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12707</td>\n",
       "      <td>9229</td>\n",
       "      <td>169519</td>\n",
       "      <td>141549</td>\n",
       "      <td>27049</td>\n",
       "      <td>28807</td>\n",
       "      <td>1603</td>\n",
       "      <td>1676</td>\n",
       "      <td>369</td>\n",
       "      <td>419</td>\n",
       "      <td>319190</td>\n",
       "      <td>285895</td>\n",
       "      <td>605085</td>\n",
       "      <td>126999</td>\n",
       "      <td>126502</td>\n",
       "      <td>124141</td>\n",
       "      <td>61570</td>\n",
       "      <td>62571</td>\n",
       "      <td>233373</td>\n",
       "      <td>109729</td>\n",
       "      <td>123644</td>\n",
       "      <td>148414</td>\n",
       "      <td>73188</td>\n",
       "      <td>75226</td>\n",
       "      <td>99157</td>\n",
       "      <td>41408</td>\n",
       "      <td>57749</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.280157</td>\n",
       "      <td>0.233932</td>\n",
       "      <td>0.044703</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.209886</td>\n",
       "      <td>0.209065</td>\n",
       "      <td>0.527513</td>\n",
       "      <td>0.472487</td>\n",
       "      <td>0.205163</td>\n",
       "      <td>0.385686</td>\n",
       "      <td>0.245278</td>\n",
       "      <td>0.163873</td>\n",
       "      <td>0.836348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>6390</td>\n",
       "      <td>9588</td>\n",
       "      <td>200013051</td>\n",
       "      <td>2000</td>\n",
       "      <td>13</td>\n",
       "      <td>51</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Chatham County</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>37847.0</td>\n",
       "      <td>37590.0</td>\n",
       "      <td>76475.0</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>60262.0</td>\n",
       "      <td>2168</td>\n",
       "      <td>1953</td>\n",
       "      <td>50551</td>\n",
       "      <td>44084</td>\n",
       "      <td>2359</td>\n",
       "      <td>3066</td>\n",
       "      <td>277</td>\n",
       "      <td>348</td>\n",
       "      <td>76</td>\n",
       "      <td>87</td>\n",
       "      <td>120422</td>\n",
       "      <td>111950</td>\n",
       "      <td>232372</td>\n",
       "      <td>66229</td>\n",
       "      <td>64405</td>\n",
       "      <td>65400</td>\n",
       "      <td>33434</td>\n",
       "      <td>31966</td>\n",
       "      <td>70045</td>\n",
       "      <td>34894</td>\n",
       "      <td>35151</td>\n",
       "      <td>58087</td>\n",
       "      <td>27490</td>\n",
       "      <td>30597</td>\n",
       "      <td>38840</td>\n",
       "      <td>16132</td>\n",
       "      <td>22708</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>0.008405</td>\n",
       "      <td>0.217543</td>\n",
       "      <td>0.189713</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.013194</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.285013</td>\n",
       "      <td>0.277163</td>\n",
       "      <td>0.518229</td>\n",
       "      <td>0.481771</td>\n",
       "      <td>0.281445</td>\n",
       "      <td>0.301435</td>\n",
       "      <td>0.249974</td>\n",
       "      <td>0.167146</td>\n",
       "      <td>-0.003361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>2366</td>\n",
       "      <td>2735</td>\n",
       "      <td>201239121</td>\n",
       "      <td>2012</td>\n",
       "      <td>39</td>\n",
       "      <td>121</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Noble County</td>\n",
       "      <td>Mitt Romney</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>3563.0</td>\n",
       "      <td>2131.0</td>\n",
       "      <td>5872.0</td>\n",
       "      <td>Mitt Romney</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>352</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6185</td>\n",
       "      <td>8476</td>\n",
       "      <td>14661</td>\n",
       "      <td>6075</td>\n",
       "      <td>8038</td>\n",
       "      <td>3098</td>\n",
       "      <td>1589</td>\n",
       "      <td>1509</td>\n",
       "      <td>2736</td>\n",
       "      <td>1337</td>\n",
       "      <td>1399</td>\n",
       "      <td>4145</td>\n",
       "      <td>2374</td>\n",
       "      <td>1771</td>\n",
       "      <td>4682</td>\n",
       "      <td>3176</td>\n",
       "      <td>1506</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.024009</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.414365</td>\n",
       "      <td>0.548257</td>\n",
       "      <td>0.421868</td>\n",
       "      <td>0.578132</td>\n",
       "      <td>0.211309</td>\n",
       "      <td>0.186618</td>\n",
       "      <td>0.282723</td>\n",
       "      <td>0.319351</td>\n",
       "      <td>-0.243869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7948</th>\n",
       "      <td>7948</td>\n",
       "      <td>11173</td>\n",
       "      <td>200037155</td>\n",
       "      <td>2000</td>\n",
       "      <td>37</td>\n",
       "      <td>155</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Robeson County</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>11721.0</td>\n",
       "      <td>17834.0</td>\n",
       "      <td>29747.0</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>23087.0</td>\n",
       "      <td>207</td>\n",
       "      <td>229</td>\n",
       "      <td>16462</td>\n",
       "      <td>14552</td>\n",
       "      <td>2204</td>\n",
       "      <td>3773</td>\n",
       "      <td>24436</td>\n",
       "      <td>22774</td>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>63266</td>\n",
       "      <td>59904</td>\n",
       "      <td>123170</td>\n",
       "      <td>21460</td>\n",
       "      <td>21709</td>\n",
       "      <td>39588</td>\n",
       "      <td>20145</td>\n",
       "      <td>19443</td>\n",
       "      <td>36326</td>\n",
       "      <td>18237</td>\n",
       "      <td>18089</td>\n",
       "      <td>30398</td>\n",
       "      <td>14695</td>\n",
       "      <td>15703</td>\n",
       "      <td>16858</td>\n",
       "      <td>6827</td>\n",
       "      <td>10031</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.133653</td>\n",
       "      <td>0.118146</td>\n",
       "      <td>0.017894</td>\n",
       "      <td>0.030632</td>\n",
       "      <td>0.198392</td>\n",
       "      <td>0.184899</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.174231</td>\n",
       "      <td>0.176252</td>\n",
       "      <td>0.513648</td>\n",
       "      <td>0.486352</td>\n",
       "      <td>0.321409</td>\n",
       "      <td>0.294926</td>\n",
       "      <td>0.246797</td>\n",
       "      <td>0.136868</td>\n",
       "      <td>0.205500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>5535</td>\n",
       "      <td>5907</td>\n",
       "      <td>201647043</td>\n",
       "      <td>2016</td>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Dickson County</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>13233.0</td>\n",
       "      <td>4722.0</td>\n",
       "      <td>18699.0</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>37736.0</td>\n",
       "      <td>161</td>\n",
       "      <td>122</td>\n",
       "      <td>1018</td>\n",
       "      <td>1105</td>\n",
       "      <td>763</td>\n",
       "      <td>826</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>25665</td>\n",
       "      <td>24808</td>\n",
       "      <td>50473</td>\n",
       "      <td>23921</td>\n",
       "      <td>22984</td>\n",
       "      <td>13040</td>\n",
       "      <td>6792</td>\n",
       "      <td>6248</td>\n",
       "      <td>12292</td>\n",
       "      <td>6092</td>\n",
       "      <td>6200</td>\n",
       "      <td>14625</td>\n",
       "      <td>7124</td>\n",
       "      <td>7501</td>\n",
       "      <td>10516</td>\n",
       "      <td>4800</td>\n",
       "      <td>5716</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.020169</td>\n",
       "      <td>0.021893</td>\n",
       "      <td>0.015117</td>\n",
       "      <td>0.016365</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.473937</td>\n",
       "      <td>0.455372</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>0.491510</td>\n",
       "      <td>0.258356</td>\n",
       "      <td>0.243536</td>\n",
       "      <td>0.289759</td>\n",
       "      <td>0.208349</td>\n",
       "      <td>-0.455158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     ID  YEAR_FIPS  YEAR  STATE_FIPS  COUNTY_FIPS  \\\n",
       "4235         4235   4606  201622071  2016          22           71   \n",
       "14679       14679  17964  200847059  2008          47           59   \n",
       "2503         2503   2872  201241065  2012          41           65   \n",
       "6700         6700   9899  200018051  2000          18           51   \n",
       "5484         5484   5855  201646073  2016          46           73   \n",
       "583           583    951  201211001  2012          11            1   \n",
       "6390         6390   9588  200013051  2000          13           51   \n",
       "2366         2366   2735  201239121  2012          39          121   \n",
       "7948         7948  11173  200037155  2000          37          155   \n",
       "5535         5535   5907  201647043  2016          47           43   \n",
       "\n",
       "                      STATE                COUNTY   REP_CANDIDATE  \\\n",
       "4235              Louisiana        Orleans Parish    Donald Trump   \n",
       "14679             Tennessee         Greene County     John McCain   \n",
       "2503                 Oregon          Wasco County     Mitt Romney   \n",
       "6700                Indiana         Gibson County  George W. Bush   \n",
       "5484           South Dakota        Jerauld County    Donald Trump   \n",
       "583    District of Columbia  District of Columbia     Mitt Romney   \n",
       "6390                Georgia        Chatham County  George W. Bush   \n",
       "2366                   Ohio          Noble County     Mitt Romney   \n",
       "7948         North Carolina        Robeson County  George W. Bush   \n",
       "5535              Tennessee        Dickson County    Donald Trump   \n",
       "\n",
       "         DEM_CANDIDATE  REP_VOTES  DEM_VOTES  COUNTY_TOTALVOTES  \\\n",
       "4235   Hillary Clinton    24292.0   133996.0           165812.0   \n",
       "14679     Barack Obama    17151.0     7110.0            24670.0   \n",
       "2503      Barack Obama     5229.0     5211.0            10873.0   \n",
       "6700           Al Gore     7734.0     5802.0            13772.0   \n",
       "5484   Hillary Clinton      648.0      264.0              967.0   \n",
       "583       Barack Obama    21381.0   267070.0           293764.0   \n",
       "6390           Al Gore    37847.0    37590.0            76475.0   \n",
       "2366      Barack Obama     3563.0     2131.0             5872.0   \n",
       "7948           Al Gore    11721.0    17834.0            29747.0   \n",
       "5535   Hillary Clinton    13233.0     4722.0            18699.0   \n",
       "\n",
       "      WINNING_CANDIDATE WINNING_PARTY  WINNING_PARTY_BINARY  \\\n",
       "4235    Hillary Clinton      democrat                     0   \n",
       "14679       John McCain    republican                     1   \n",
       "2503        Mitt Romney    republican                     1   \n",
       "6700     George W. Bush    republican                     1   \n",
       "5484       Donald Trump    republican                     1   \n",
       "583        Barack Obama      democrat                     0   \n",
       "6390     George W. Bush    republican                     1   \n",
       "2366        Mitt Romney    republican                     1   \n",
       "7948            Al Gore      democrat                     0   \n",
       "5535       Donald Trump    republican                     1   \n",
       "\n",
       "       HOUSE_WINNING_BINARY  SENATE_WINNING_BINARY  UNEMPLOYMENT_RATE  \\\n",
       "4235                      1                      1                5.9   \n",
       "14679                     1                      1                9.3   \n",
       "2503                      0                     -1                8.4   \n",
       "6700                      1                      1                3.4   \n",
       "5484                      1                      1                2.4   \n",
       "583                      -1                     -1                9.0   \n",
       "6390                      1                      0                3.6   \n",
       "2366                      0                      0               11.0   \n",
       "7948                      0                     -1                6.6   \n",
       "5535                      1                     -1                4.3   \n",
       "\n",
       "       AVG_WAGE_SALARY  AA_FEMALE  AA_MALE  BA_FEMALE  BA_MALE  H_FEMALE  \\\n",
       "4235          151464.0       5614     5534     126132   106710      9419   \n",
       "14679              0.0        127      112        679      719       627   \n",
       "2503           36244.0        121       85         51       68      1782   \n",
       "6700           59266.0         53      118        303      326       113   \n",
       "5484           34777.0          4        2          1        2        40   \n",
       "583                0.0      12707     9229     169519   141549     27049   \n",
       "6390           60262.0       2168     1953      50551    44084      2359   \n",
       "2366               0.0         16        7         17      352        18   \n",
       "7948           23087.0        207      229      16462    14552      2204   \n",
       "5535           37736.0        161      122       1018     1105       763   \n",
       "\n",
       "       H_MALE  IA_FEMALE  IA_MALE  NA_FEMALE  NA_MALE  TOT_FEMALE  TOT_MALE  \\\n",
       "4235    11258        590      738        109      149      200441    183489   \n",
       "14679     863        106       76         21       29       34562     33278   \n",
       "2503     2016        589      617         86       78       12748     12537   \n",
       "6700      116         37       24          0        1       16584     15889   \n",
       "5484       49          5        6          3        0        1031      1010   \n",
       "583     28807       1603     1676        369      419      319190    285895   \n",
       "6390     3066        277      348         76       87      120422    111950   \n",
       "2366       34         21       22          2        1        6185      8476   \n",
       "7948     3773      24436    22774         40       58       63266     59904   \n",
       "5535      826        113      119          9       16       25665     24808   \n",
       "\n",
       "       TOT_POP  WA_FEMALE  WA_MALE  TOT_POP_LESS19  TOT_MALE_LESS19  \\\n",
       "4235    383930      65018    67765           88156            44430   \n",
       "14679    67840      33320    32058           16483             8543   \n",
       "2503     25285      11656    11413            6483             3325   \n",
       "6700     32473      16087    15325            8942             4576   \n",
       "5484      2041       1007      993             505              274   \n",
       "583     605085     126999   126502          124141            61570   \n",
       "6390    232372      66229    64405           65400            33434   \n",
       "2366     14661       6075     8038            3098             1589   \n",
       "7948    123170      21460    21709           39588            20145   \n",
       "5535     50473      23921    22984           13040             6792   \n",
       "\n",
       "       TOT_FEMALE_LESS19  TOT_POP_20to39  TOT_MALE_20to39  TOT_FEMALE_20to39  \\\n",
       "4235               43726          125685            60041              65644   \n",
       "14679               7940           16045             8142               7903   \n",
       "2503                3158            5638             2856               2782   \n",
       "6700                4366            8296             4249               4047   \n",
       "5484                 231             370              192                178   \n",
       "583                62571          233373           109729             123644   \n",
       "6390               31966           70045            34894              35151   \n",
       "2366                1509            2736             1337               1399   \n",
       "7948               19443           36326            18237              18089   \n",
       "5535                6248           12292             6092               6200   \n",
       "\n",
       "       TOT_POP_40to59  TOT_MALE_40to59  TOT_FEMALE_40to59  TOT_POP_Above60  \\\n",
       "4235            99227            47874              51353            70862   \n",
       "14679           19917             9716              10201            15395   \n",
       "2503             6853             3391               3462             6311   \n",
       "6700             8718             4357               4361             6517   \n",
       "5484              466              248                218              700   \n",
       "583            148414            73188              75226            99157   \n",
       "6390            58087            27490              30597            38840   \n",
       "2366             4145             2374               1771             4682   \n",
       "7948            30398            14695              15703            16858   \n",
       "5535            14625             7124               7501            10516   \n",
       "\n",
       "       TOT_MALE_Above60  TOT_FEMALE_Above60  AA_FEMALE%  AA_MALE%  BA_FEMALE%  \\\n",
       "4235              31144               39718    0.014622  0.014414    0.328529   \n",
       "14679              6877                8518    0.001872  0.001651    0.010009   \n",
       "2503               2965                3346    0.004785  0.003362    0.002017   \n",
       "6700               2707                3810    0.001632  0.003634    0.009331   \n",
       "5484                296                 404    0.001960  0.000980    0.000490   \n",
       "583               41408               57749    0.021000  0.015252    0.280157   \n",
       "6390              16132               22708    0.009330  0.008405    0.217543   \n",
       "2366               3176                1506    0.001091  0.000477    0.001160   \n",
       "7948               6827               10031    0.001681  0.001859    0.133653   \n",
       "5535               4800                5716    0.003190  0.002417    0.020169   \n",
       "\n",
       "       BA_MALE%  H_FEMALE%   H_MALE%  IA_FEMALE%  IA_MALE%  NA_FEMALE%  \\\n",
       "4235   0.277941   0.024533  0.029323    0.001537  0.001922    0.000284   \n",
       "14679  0.010598   0.009242  0.012721    0.001563  0.001120    0.000310   \n",
       "2503   0.002689   0.070477  0.079731    0.023294  0.024402    0.003401   \n",
       "6700   0.010039   0.003480  0.003572    0.001139  0.000739    0.000000   \n",
       "5484   0.000980   0.019598  0.024008    0.002450  0.002940    0.001470   \n",
       "583    0.233932   0.044703  0.047608    0.002649  0.002770    0.000610   \n",
       "6390   0.189713   0.010152  0.013194    0.001192  0.001498    0.000327   \n",
       "2366   0.024009   0.001228  0.002319    0.001432  0.001501    0.000136   \n",
       "7948   0.118146   0.017894  0.030632    0.198392  0.184899    0.000325   \n",
       "5535   0.021893   0.015117  0.016365    0.002239  0.002358    0.000178   \n",
       "\n",
       "       NA_MALE%  WA_FEMALE%  WA_MALE%  TOT_FEMALE%  TOT_MALE%  \\\n",
       "4235   0.000388    0.169349  0.176504     0.522077   0.477923   \n",
       "14679  0.000427    0.491156  0.472553     0.509463   0.490537   \n",
       "2503   0.003085    0.460985  0.451374     0.504172   0.495828   \n",
       "6700   0.000031    0.495396  0.471931     0.510701   0.489299   \n",
       "5484   0.000000    0.493386  0.486526     0.505145   0.494855   \n",
       "583    0.000692    0.209886  0.209065     0.527513   0.472487   \n",
       "6390   0.000374    0.285013  0.277163     0.518229   0.481771   \n",
       "2366   0.000068    0.414365  0.548257     0.421868   0.578132   \n",
       "7948   0.000471    0.174231  0.176252     0.513648   0.486352   \n",
       "5535   0.000317    0.473937  0.455372     0.508490   0.491510   \n",
       "\n",
       "       TOT_POP_LESS19%  TOT_POP_20to39%  TOT_POP_40to59%  TOT_POP_Above60%  \\\n",
       "4235          0.229615         0.327364         0.258451          0.184570   \n",
       "14679         0.242969         0.236512         0.293588          0.226931   \n",
       "2503          0.256397         0.222978         0.271030          0.249595   \n",
       "6700          0.275367         0.255474         0.268469          0.200690   \n",
       "5484          0.247428         0.181284         0.228319          0.342969   \n",
       "583           0.205163         0.385686         0.245278          0.163873   \n",
       "6390          0.281445         0.301435         0.249974          0.167146   \n",
       "2366          0.211309         0.186618         0.282723          0.319351   \n",
       "7948          0.321409         0.294926         0.246797          0.136868   \n",
       "5535          0.258356         0.243536         0.289759          0.208349   \n",
       "\n",
       "       MARGIN_VICTORY  TRAIN  \n",
       "4235         0.661617      0  \n",
       "14679       -0.407013      0  \n",
       "2503        -0.001655      0  \n",
       "6700        -0.140285      0  \n",
       "5484        -0.397104      0  \n",
       "583          0.836348      0  \n",
       "6390        -0.003361      0  \n",
       "2366        -0.243869      0  \n",
       "7948         0.205500      0  \n",
       "5535        -0.455158      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "ID                  0\n",
       "YEAR_FIPS           0\n",
       "YEAR                0\n",
       "STATE_FIPS          0\n",
       "                   ..\n",
       "TOT_POP_20to39%     0\n",
       "TOT_POP_40to59%     0\n",
       "TOT_POP_Above60%    0\n",
       "MARGIN_VICTORY      0\n",
       "TRAIN               0\n",
       "Length: 67, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## some cleanup..\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "ID                  0\n",
       "YEAR_FIPS           0\n",
       "YEAR                0\n",
       "STATE_FIPS          0\n",
       "                   ..\n",
       "TOT_POP_20to39%     0\n",
       "TOT_POP_40to59%     0\n",
       "TOT_POP_Above60%    0\n",
       "MARGIN_VICTORY      0\n",
       "TRAIN               0\n",
       "Length: 67, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15569 entries, 0 to 15568\n",
      "Data columns (total 67 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             15569 non-null  int64  \n",
      " 1   ID                     15569 non-null  int64  \n",
      " 2   YEAR_FIPS              15569 non-null  int64  \n",
      " 3   YEAR                   15569 non-null  int64  \n",
      " 4   STATE_FIPS             15569 non-null  int64  \n",
      " 5   COUNTY_FIPS            15569 non-null  int64  \n",
      " 6   STATE                  15569 non-null  object \n",
      " 7   COUNTY                 15569 non-null  object \n",
      " 8   REP_CANDIDATE          15569 non-null  object \n",
      " 9   DEM_CANDIDATE          15569 non-null  object \n",
      " 10  REP_VOTES              15569 non-null  float64\n",
      " 11  DEM_VOTES              15569 non-null  float64\n",
      " 12  COUNTY_TOTALVOTES      15569 non-null  float64\n",
      " 13  WINNING_CANDIDATE      15569 non-null  object \n",
      " 14  WINNING_PARTY          15569 non-null  object \n",
      " 15  WINNING_PARTY_BINARY   15569 non-null  int64  \n",
      " 16  HOUSE_WINNING_BINARY   15569 non-null  int64  \n",
      " 17  SENATE_WINNING_BINARY  15569 non-null  int64  \n",
      " 18  UNEMPLOYMENT_RATE      15569 non-null  float64\n",
      " 19  AVG_WAGE_SALARY        15569 non-null  float64\n",
      " 20  AA_FEMALE              15569 non-null  int64  \n",
      " 21  AA_MALE                15569 non-null  int64  \n",
      " 22  BA_FEMALE              15569 non-null  int64  \n",
      " 23  BA_MALE                15569 non-null  int64  \n",
      " 24  H_FEMALE               15569 non-null  int64  \n",
      " 25  H_MALE                 15569 non-null  int64  \n",
      " 26  IA_FEMALE              15569 non-null  int64  \n",
      " 27  IA_MALE                15569 non-null  int64  \n",
      " 28  NA_FEMALE              15569 non-null  int64  \n",
      " 29  NA_MALE                15569 non-null  int64  \n",
      " 30  TOT_FEMALE             15569 non-null  int64  \n",
      " 31  TOT_MALE               15569 non-null  int64  \n",
      " 32  TOT_POP                15569 non-null  int64  \n",
      " 33  WA_FEMALE              15569 non-null  int64  \n",
      " 34  WA_MALE                15569 non-null  int64  \n",
      " 35  TOT_POP_LESS19         15569 non-null  int64  \n",
      " 36  TOT_MALE_LESS19        15569 non-null  int64  \n",
      " 37  TOT_FEMALE_LESS19      15569 non-null  int64  \n",
      " 38  TOT_POP_20to39         15569 non-null  int64  \n",
      " 39  TOT_MALE_20to39        15569 non-null  int64  \n",
      " 40  TOT_FEMALE_20to39      15569 non-null  int64  \n",
      " 41  TOT_POP_40to59         15569 non-null  int64  \n",
      " 42  TOT_MALE_40to59        15569 non-null  int64  \n",
      " 43  TOT_FEMALE_40to59      15569 non-null  int64  \n",
      " 44  TOT_POP_Above60        15569 non-null  int64  \n",
      " 45  TOT_MALE_Above60       15569 non-null  int64  \n",
      " 46  TOT_FEMALE_Above60     15569 non-null  int64  \n",
      " 47  AA_FEMALE%             15569 non-null  float64\n",
      " 48  AA_MALE%               15569 non-null  float64\n",
      " 49  BA_FEMALE%             15569 non-null  float64\n",
      " 50  BA_MALE%               15569 non-null  float64\n",
      " 51  H_FEMALE%              15569 non-null  float64\n",
      " 52  H_MALE%                15569 non-null  float64\n",
      " 53  IA_FEMALE%             15569 non-null  float64\n",
      " 54  IA_MALE%               15569 non-null  float64\n",
      " 55  NA_FEMALE%             15569 non-null  float64\n",
      " 56  NA_MALE%               15569 non-null  float64\n",
      " 57  WA_FEMALE%             15569 non-null  float64\n",
      " 58  WA_MALE%               15569 non-null  float64\n",
      " 59  TOT_FEMALE%            15569 non-null  float64\n",
      " 60  TOT_MALE%              15569 non-null  float64\n",
      " 61  TOT_POP_LESS19%        15569 non-null  float64\n",
      " 62  TOT_POP_20to39%        15569 non-null  float64\n",
      " 63  TOT_POP_40to59%        15569 non-null  float64\n",
      " 64  TOT_POP_Above60%       15569 non-null  float64\n",
      " 65  MARGIN_VICTORY         15569 non-null  float64\n",
      " 66  TRAIN                  15569 non-null  int64  \n",
      "dtypes: float64(24), int64(37), object(6)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning/wrangling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['state'] = data['state'].astype('category').cat.codes\n",
    "# data['state_po'] = data['state_po'].astype('category').cat.codes\n",
    "# data['county'] = data['county'].astype('category').cat.codes\n",
    "# data['winning party'] = data['winning party'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "* splits the `X` dataframe into test and training buckets according to the supplied year. For instance, if we want to \n",
    "test for 2016, the supplied year should be 2016. This function will make sure that the train buckets do not include\n",
    "data from 2016. \n",
    "\n",
    "* set `train_filter` if you want to make sure to only include counties with TRAIN=1 label in the training sets. These \n",
    "counties have voted at least once to each party. \n",
    "\n",
    "* set the columns in the trainign set if deseried. \n",
    "\n",
    "\"\"\"\n",
    "def train_test_split_by_year(X, year, train_filter=False, cols=None):\n",
    "    X_copy = X\n",
    "    \n",
    "    filter_year =  X['YEAR'] == year\n",
    "    not_filter_year =  X['YEAR'] != year\n",
    "\n",
    "    X_test = X[filter_year]\n",
    "    \n",
    "    if (cols != None):\n",
    "        X_test = X_test[cols]\n",
    "    \n",
    "    X_test = X_test.drop(\"WINNING_PARTY_BINARY\", axis=1)\n",
    "    print('X_test: {}'.format(X_test.shape))\n",
    "    \n",
    "    y_test = X[filter_year]\n",
    "    y_test = y_test[\"WINNING_PARTY_BINARY\"]\n",
    "    print('y_test: {}'.format(y_test.shape))\n",
    "    \n",
    "    \n",
    "    if (train_filter == True):\n",
    "        X_copy = X_copy.query('TRAIN == 1')\n",
    "        X_copy = X_copy.reset_index(drop=True)\n",
    "            \n",
    "    X_train = X_copy[not_filter_year]\n",
    "    \n",
    "    if (cols != None):\n",
    "        X_train = X_train[cols]\n",
    "   \n",
    "    X_train = X_train.drop(\"WINNING_PARTY_BINARY\", axis=1)\n",
    "\n",
    "    y_train = X_copy[not_filter_year]\n",
    "    y_train = y_train[\"WINNING_PARTY_BINARY\"]\n",
    "    \n",
    "    print('X_train: {}'.format(X_train.shape))\n",
    "    print('y_train: {}'.format(y_train.shape))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_year_2(X, year, train_filter=False, cols=None):\n",
    "    \n",
    "    X = data.drop(\"WINNING_PARTY_BINARY\", axis=1)\n",
    "    y = data[[\"WINNING_PARTY_BINARY\", \"TRAIN\"]]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "    \n",
    "    filter_year =  X['YEAR'] == year\n",
    "    not_filter_year =  X['YEAR'] != year\n",
    "    \n",
    "    X_test = X_test[filter_year]\n",
    "    \n",
    "    if (cols != None):\n",
    "        X_test = X_test[cols]\n",
    "    \n",
    "    print('X_test: {}'.format(X_test.shape))\n",
    "    \n",
    "    y_test = y_test[filter_year]\n",
    "    y_test = y_test.drop(\"TRAIN\", axis=1)\n",
    "    print('y_test: {}'.format(y_test.shape))\n",
    "\n",
    "    X_train = X_train[not_filter_year]\n",
    "\n",
    "    if (train_filter == True):\n",
    "        X_train = X_train.query('TRAIN == 1')\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "        \n",
    "    X_train.drop(\"TRAIN\", axis=1)\n",
    "    \n",
    "    if (cols != None):\n",
    "        X_train = X_train[cols]\n",
    "   \n",
    "    y_train = y_train[not_filter_year]\n",
    "    \n",
    "    if (train_filter == True):\n",
    "        y_train = y_train.query('TRAIN == 1')\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "        \n",
    "    y_train = y_train.drop(\"TRAIN\", axis=1)\n",
    "    \n",
    "    print('X_train: {}'.format(X_train.shape))\n",
    "    print('y_train: {}'.format(y_train.shape))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - Train with the data as is -- i.e without balancing training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/combined_jun22_train.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['ID', 'Unnamed: 0', 'STATE_FIPS', 'COUNTY_FIPS', 'WINNING_CANDIDATE', 'REP_CANDIDATE', 'DEM_CANDIDATE', 'WINNING_PARTY', 'COUNTY', 'STATE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: (3114, 56)\n",
      "y_test: (3114,)\n",
      "X_train: (12455, 56)\n",
      "y_train: (12455,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_by_year(data, year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: (957, 56)\n",
      "y_test: (957, 1)\n",
      "X_train: (8741, 56)\n",
      "y_train: (8741, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:33: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_by_year_2(data, year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR_FIPS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>REP_VOTES</th>\n",
       "      <th>DEM_VOTES</th>\n",
       "      <th>COUNTY_TOTALVOTES</th>\n",
       "      <th>HOUSE_WINNING_BINARY</th>\n",
       "      <th>SENATE_WINNING_BINARY</th>\n",
       "      <th>UNEMPLOYMENT_RATE</th>\n",
       "      <th>AVG_WAGE_SALARY</th>\n",
       "      <th>AA_FEMALE</th>\n",
       "      <th>AA_MALE</th>\n",
       "      <th>BA_FEMALE</th>\n",
       "      <th>BA_MALE</th>\n",
       "      <th>H_FEMALE</th>\n",
       "      <th>H_MALE</th>\n",
       "      <th>IA_FEMALE</th>\n",
       "      <th>IA_MALE</th>\n",
       "      <th>NA_FEMALE</th>\n",
       "      <th>NA_MALE</th>\n",
       "      <th>TOT_FEMALE</th>\n",
       "      <th>TOT_MALE</th>\n",
       "      <th>TOT_POP</th>\n",
       "      <th>WA_FEMALE</th>\n",
       "      <th>WA_MALE</th>\n",
       "      <th>TOT_POP_LESS19</th>\n",
       "      <th>TOT_MALE_LESS19</th>\n",
       "      <th>TOT_FEMALE_LESS19</th>\n",
       "      <th>TOT_POP_20to39</th>\n",
       "      <th>TOT_MALE_20to39</th>\n",
       "      <th>TOT_FEMALE_20to39</th>\n",
       "      <th>TOT_POP_40to59</th>\n",
       "      <th>TOT_MALE_40to59</th>\n",
       "      <th>TOT_FEMALE_40to59</th>\n",
       "      <th>TOT_POP_Above60</th>\n",
       "      <th>TOT_MALE_Above60</th>\n",
       "      <th>TOT_FEMALE_Above60</th>\n",
       "      <th>AA_FEMALE%</th>\n",
       "      <th>AA_MALE%</th>\n",
       "      <th>BA_FEMALE%</th>\n",
       "      <th>BA_MALE%</th>\n",
       "      <th>H_FEMALE%</th>\n",
       "      <th>H_MALE%</th>\n",
       "      <th>IA_FEMALE%</th>\n",
       "      <th>IA_MALE%</th>\n",
       "      <th>NA_FEMALE%</th>\n",
       "      <th>NA_MALE%</th>\n",
       "      <th>WA_FEMALE%</th>\n",
       "      <th>WA_MALE%</th>\n",
       "      <th>TOT_FEMALE%</th>\n",
       "      <th>TOT_MALE%</th>\n",
       "      <th>TOT_POP_LESS19%</th>\n",
       "      <th>TOT_POP_20to39%</th>\n",
       "      <th>TOT_POP_40to59%</th>\n",
       "      <th>TOT_POP_Above60%</th>\n",
       "      <th>MARGIN_VICTORY</th>\n",
       "      <th>TRAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [YEAR_FIPS, YEAR, REP_VOTES, DEM_VOTES, COUNTY_TOTALVOTES, HOUSE_WINNING_BINARY, SENATE_WINNING_BINARY, UNEMPLOYMENT_RATE, AVG_WAGE_SALARY, AA_FEMALE, AA_MALE, BA_FEMALE, BA_MALE, H_FEMALE, H_MALE, IA_FEMALE, IA_MALE, NA_FEMALE, NA_MALE, TOT_FEMALE, TOT_MALE, TOT_POP, WA_FEMALE, WA_MALE, TOT_POP_LESS19, TOT_MALE_LESS19, TOT_FEMALE_LESS19, TOT_POP_20to39, TOT_MALE_20to39, TOT_FEMALE_20to39, TOT_POP_40to59, TOT_MALE_40to59, TOT_FEMALE_40to59, TOT_POP_Above60, TOT_MALE_Above60, TOT_FEMALE_Above60, AA_FEMALE%, AA_MALE%, BA_FEMALE%, BA_MALE%, H_FEMALE%, H_MALE%, IA_FEMALE%, IA_MALE%, NA_FEMALE%, NA_MALE%, WA_FEMALE%, WA_MALE%, TOT_FEMALE%, TOT_MALE%, TOT_POP_LESS19%, TOT_POP_20to39%, TOT_POP_40to59%, TOT_POP_Above60%, MARGIN_VICTORY, TRAIN]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[X_train['YEAR'] == year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR_FIPS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>REP_VOTES</th>\n",
       "      <th>DEM_VOTES</th>\n",
       "      <th>COUNTY_TOTALVOTES</th>\n",
       "      <th>HOUSE_WINNING_BINARY</th>\n",
       "      <th>SENATE_WINNING_BINARY</th>\n",
       "      <th>UNEMPLOYMENT_RATE</th>\n",
       "      <th>AVG_WAGE_SALARY</th>\n",
       "      <th>AA_FEMALE</th>\n",
       "      <th>AA_MALE</th>\n",
       "      <th>BA_FEMALE</th>\n",
       "      <th>BA_MALE</th>\n",
       "      <th>H_FEMALE</th>\n",
       "      <th>H_MALE</th>\n",
       "      <th>IA_FEMALE</th>\n",
       "      <th>IA_MALE</th>\n",
       "      <th>NA_FEMALE</th>\n",
       "      <th>NA_MALE</th>\n",
       "      <th>TOT_FEMALE</th>\n",
       "      <th>TOT_MALE</th>\n",
       "      <th>TOT_POP</th>\n",
       "      <th>WA_FEMALE</th>\n",
       "      <th>WA_MALE</th>\n",
       "      <th>TOT_POP_LESS19</th>\n",
       "      <th>TOT_MALE_LESS19</th>\n",
       "      <th>TOT_FEMALE_LESS19</th>\n",
       "      <th>TOT_POP_20to39</th>\n",
       "      <th>TOT_MALE_20to39</th>\n",
       "      <th>TOT_FEMALE_20to39</th>\n",
       "      <th>TOT_POP_40to59</th>\n",
       "      <th>TOT_MALE_40to59</th>\n",
       "      <th>TOT_FEMALE_40to59</th>\n",
       "      <th>TOT_POP_Above60</th>\n",
       "      <th>TOT_MALE_Above60</th>\n",
       "      <th>TOT_FEMALE_Above60</th>\n",
       "      <th>AA_FEMALE%</th>\n",
       "      <th>AA_MALE%</th>\n",
       "      <th>BA_FEMALE%</th>\n",
       "      <th>BA_MALE%</th>\n",
       "      <th>H_FEMALE%</th>\n",
       "      <th>H_MALE%</th>\n",
       "      <th>IA_FEMALE%</th>\n",
       "      <th>IA_MALE%</th>\n",
       "      <th>NA_FEMALE%</th>\n",
       "      <th>NA_MALE%</th>\n",
       "      <th>WA_FEMALE%</th>\n",
       "      <th>WA_MALE%</th>\n",
       "      <th>TOT_FEMALE%</th>\n",
       "      <th>TOT_MALE%</th>\n",
       "      <th>TOT_POP_LESS19%</th>\n",
       "      <th>TOT_POP_20to39%</th>\n",
       "      <th>TOT_POP_40to59%</th>\n",
       "      <th>TOT_POP_Above60%</th>\n",
       "      <th>MARGIN_VICTORY</th>\n",
       "      <th>TRAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>201616015</td>\n",
       "      <td>2016</td>\n",
       "      <td>2673.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>3814.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>29404.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>118</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3274</td>\n",
       "      <td>3506</td>\n",
       "      <td>6780</td>\n",
       "      <td>3100</td>\n",
       "      <td>3364</td>\n",
       "      <td>1378</td>\n",
       "      <td>724</td>\n",
       "      <td>654</td>\n",
       "      <td>1007</td>\n",
       "      <td>510</td>\n",
       "      <td>497</td>\n",
       "      <td>2151</td>\n",
       "      <td>1053</td>\n",
       "      <td>1098</td>\n",
       "      <td>2244</td>\n",
       "      <td>1219</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.019027</td>\n",
       "      <td>0.017404</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.457227</td>\n",
       "      <td>0.496165</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>0.517109</td>\n",
       "      <td>0.203245</td>\n",
       "      <td>0.148525</td>\n",
       "      <td>0.317257</td>\n",
       "      <td>0.330973</td>\n",
       "      <td>-0.497116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5186</th>\n",
       "      <td>201639113</td>\n",
       "      <td>2016</td>\n",
       "      <td>123909.0</td>\n",
       "      <td>122016.0</td>\n",
       "      <td>258301.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5929</td>\n",
       "      <td>5088</td>\n",
       "      <td>60343</td>\n",
       "      <td>52438</td>\n",
       "      <td>6748</td>\n",
       "      <td>7158</td>\n",
       "      <td>664</td>\n",
       "      <td>738</td>\n",
       "      <td>153</td>\n",
       "      <td>121</td>\n",
       "      <td>276368</td>\n",
       "      <td>256101</td>\n",
       "      <td>532469</td>\n",
       "      <td>202227</td>\n",
       "      <td>191271</td>\n",
       "      <td>133218</td>\n",
       "      <td>68087</td>\n",
       "      <td>65131</td>\n",
       "      <td>136568</td>\n",
       "      <td>67271</td>\n",
       "      <td>69297</td>\n",
       "      <td>140900</td>\n",
       "      <td>68006</td>\n",
       "      <td>72894</td>\n",
       "      <td>121783</td>\n",
       "      <td>52737</td>\n",
       "      <td>69046</td>\n",
       "      <td>0.011135</td>\n",
       "      <td>0.009555</td>\n",
       "      <td>0.113327</td>\n",
       "      <td>0.098481</td>\n",
       "      <td>0.012673</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.379791</td>\n",
       "      <td>0.359215</td>\n",
       "      <td>0.519031</td>\n",
       "      <td>0.480969</td>\n",
       "      <td>0.250189</td>\n",
       "      <td>0.256481</td>\n",
       "      <td>0.264616</td>\n",
       "      <td>0.228714</td>\n",
       "      <td>-0.007329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>20164019</td>\n",
       "      <td>2016</td>\n",
       "      <td>167428.0</td>\n",
       "      <td>224661.0</td>\n",
       "      <td>421640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>44683.0</td>\n",
       "      <td>17216</td>\n",
       "      <td>14749</td>\n",
       "      <td>18804</td>\n",
       "      <td>22279</td>\n",
       "      <td>185550</td>\n",
       "      <td>178030</td>\n",
       "      <td>21664</td>\n",
       "      <td>20993</td>\n",
       "      <td>1152</td>\n",
       "      <td>1124</td>\n",
       "      <td>509783</td>\n",
       "      <td>494892</td>\n",
       "      <td>1004675</td>\n",
       "      <td>436929</td>\n",
       "      <td>421722</td>\n",
       "      <td>251775</td>\n",
       "      <td>128334</td>\n",
       "      <td>123441</td>\n",
       "      <td>274068</td>\n",
       "      <td>140404</td>\n",
       "      <td>133664</td>\n",
       "      <td>241237</td>\n",
       "      <td>117731</td>\n",
       "      <td>123506</td>\n",
       "      <td>237595</td>\n",
       "      <td>108423</td>\n",
       "      <td>129172</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.022175</td>\n",
       "      <td>0.184687</td>\n",
       "      <td>0.177202</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>0.020895</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.434896</td>\n",
       "      <td>0.419760</td>\n",
       "      <td>0.507411</td>\n",
       "      <td>0.492589</td>\n",
       "      <td>0.250603</td>\n",
       "      <td>0.272793</td>\n",
       "      <td>0.240114</td>\n",
       "      <td>0.236489</td>\n",
       "      <td>0.135739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4726</th>\n",
       "      <td>201630083</td>\n",
       "      <td>2016</td>\n",
       "      <td>3908.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>4871.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>255</td>\n",
       "      <td>326</td>\n",
       "      <td>107</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5515</td>\n",
       "      <td>6016</td>\n",
       "      <td>11531</td>\n",
       "      <td>5221</td>\n",
       "      <td>5694</td>\n",
       "      <td>3115</td>\n",
       "      <td>1570</td>\n",
       "      <td>1545</td>\n",
       "      <td>3045</td>\n",
       "      <td>1669</td>\n",
       "      <td>1376</td>\n",
       "      <td>3156</td>\n",
       "      <td>1659</td>\n",
       "      <td>1497</td>\n",
       "      <td>2215</td>\n",
       "      <td>1118</td>\n",
       "      <td>1097</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.022114</td>\n",
       "      <td>0.028272</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.452779</td>\n",
       "      <td>0.493799</td>\n",
       "      <td>0.478276</td>\n",
       "      <td>0.521724</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>0.264071</td>\n",
       "      <td>0.273697</td>\n",
       "      <td>0.192091</td>\n",
       "      <td>-0.664545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>201613149</td>\n",
       "      <td>2016</td>\n",
       "      <td>3370.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>4223.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>48823.0</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>620</td>\n",
       "      <td>546</td>\n",
       "      <td>131</td>\n",
       "      <td>173</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5821</td>\n",
       "      <td>5798</td>\n",
       "      <td>11619</td>\n",
       "      <td>5034</td>\n",
       "      <td>5079</td>\n",
       "      <td>3012</td>\n",
       "      <td>1566</td>\n",
       "      <td>1446</td>\n",
       "      <td>2631</td>\n",
       "      <td>1335</td>\n",
       "      <td>1296</td>\n",
       "      <td>3374</td>\n",
       "      <td>1676</td>\n",
       "      <td>1698</td>\n",
       "      <td>2602</td>\n",
       "      <td>1221</td>\n",
       "      <td>1381</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.053361</td>\n",
       "      <td>0.046992</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>0.014889</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.433256</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.500990</td>\n",
       "      <td>0.499010</td>\n",
       "      <td>0.259231</td>\n",
       "      <td>0.226439</td>\n",
       "      <td>0.290386</td>\n",
       "      <td>0.223944</td>\n",
       "      <td>-0.622070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>20161125</td>\n",
       "      <td>2016</td>\n",
       "      <td>47723.0</td>\n",
       "      <td>31762.0</td>\n",
       "      <td>82700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>42119.0</td>\n",
       "      <td>1595</td>\n",
       "      <td>1543</td>\n",
       "      <td>34088</td>\n",
       "      <td>28834</td>\n",
       "      <td>3137</td>\n",
       "      <td>3677</td>\n",
       "      <td>321</td>\n",
       "      <td>352</td>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>104944</td>\n",
       "      <td>98153</td>\n",
       "      <td>203097</td>\n",
       "      <td>67727</td>\n",
       "      <td>66265</td>\n",
       "      <td>52854</td>\n",
       "      <td>26519</td>\n",
       "      <td>26335</td>\n",
       "      <td>68277</td>\n",
       "      <td>33743</td>\n",
       "      <td>34534</td>\n",
       "      <td>47033</td>\n",
       "      <td>22511</td>\n",
       "      <td>24522</td>\n",
       "      <td>34933</td>\n",
       "      <td>15380</td>\n",
       "      <td>19553</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.167841</td>\n",
       "      <td>0.141972</td>\n",
       "      <td>0.015446</td>\n",
       "      <td>0.018105</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.333471</td>\n",
       "      <td>0.326273</td>\n",
       "      <td>0.516719</td>\n",
       "      <td>0.483281</td>\n",
       "      <td>0.260240</td>\n",
       "      <td>0.336179</td>\n",
       "      <td>0.231579</td>\n",
       "      <td>0.172002</td>\n",
       "      <td>-0.192999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>201653025</td>\n",
       "      <td>2016</td>\n",
       "      <td>18518.0</td>\n",
       "      <td>7810.0</td>\n",
       "      <td>28346.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>507</td>\n",
       "      <td>464</td>\n",
       "      <td>716</td>\n",
       "      <td>920</td>\n",
       "      <td>18009</td>\n",
       "      <td>19365</td>\n",
       "      <td>982</td>\n",
       "      <td>947</td>\n",
       "      <td>72</td>\n",
       "      <td>75</td>\n",
       "      <td>45882</td>\n",
       "      <td>47086</td>\n",
       "      <td>92968</td>\n",
       "      <td>42504</td>\n",
       "      <td>43659</td>\n",
       "      <td>30625</td>\n",
       "      <td>15413</td>\n",
       "      <td>15212</td>\n",
       "      <td>24484</td>\n",
       "      <td>12768</td>\n",
       "      <td>11716</td>\n",
       "      <td>21380</td>\n",
       "      <td>10942</td>\n",
       "      <td>10438</td>\n",
       "      <td>16479</td>\n",
       "      <td>7963</td>\n",
       "      <td>8516</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.193712</td>\n",
       "      <td>0.208297</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.457190</td>\n",
       "      <td>0.469613</td>\n",
       "      <td>0.493525</td>\n",
       "      <td>0.506475</td>\n",
       "      <td>0.329414</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.229972</td>\n",
       "      <td>0.177255</td>\n",
       "      <td>-0.377761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>20166095</td>\n",
       "      <td>2016</td>\n",
       "      <td>51920.0</td>\n",
       "      <td>102360.0</td>\n",
       "      <td>166113.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>56189.0</td>\n",
       "      <td>35922</td>\n",
       "      <td>30384</td>\n",
       "      <td>31926</td>\n",
       "      <td>32195</td>\n",
       "      <td>53060</td>\n",
       "      <td>55693</td>\n",
       "      <td>2575</td>\n",
       "      <td>2712</td>\n",
       "      <td>2194</td>\n",
       "      <td>2187</td>\n",
       "      <td>215883</td>\n",
       "      <td>213272</td>\n",
       "      <td>429155</td>\n",
       "      <td>128494</td>\n",
       "      <td>131478</td>\n",
       "      <td>108866</td>\n",
       "      <td>55825</td>\n",
       "      <td>53041</td>\n",
       "      <td>118148</td>\n",
       "      <td>61056</td>\n",
       "      <td>57092</td>\n",
       "      <td>117520</td>\n",
       "      <td>58095</td>\n",
       "      <td>59425</td>\n",
       "      <td>84621</td>\n",
       "      <td>38296</td>\n",
       "      <td>46325</td>\n",
       "      <td>0.083704</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.074393</td>\n",
       "      <td>0.075020</td>\n",
       "      <td>0.123638</td>\n",
       "      <td>0.129774</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.299412</td>\n",
       "      <td>0.306365</td>\n",
       "      <td>0.503042</td>\n",
       "      <td>0.496958</td>\n",
       "      <td>0.253675</td>\n",
       "      <td>0.275304</td>\n",
       "      <td>0.273840</td>\n",
       "      <td>0.197181</td>\n",
       "      <td>0.303649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3673</th>\n",
       "      <td>201616071</td>\n",
       "      <td>2016</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>2068.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>80154.0</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2081</td>\n",
       "      <td>2095</td>\n",
       "      <td>4176</td>\n",
       "      <td>2029</td>\n",
       "      <td>2043</td>\n",
       "      <td>1279</td>\n",
       "      <td>656</td>\n",
       "      <td>623</td>\n",
       "      <td>794</td>\n",
       "      <td>390</td>\n",
       "      <td>404</td>\n",
       "      <td>1030</td>\n",
       "      <td>519</td>\n",
       "      <td>511</td>\n",
       "      <td>1073</td>\n",
       "      <td>530</td>\n",
       "      <td>543</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>0.018439</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.485872</td>\n",
       "      <td>0.489224</td>\n",
       "      <td>0.498324</td>\n",
       "      <td>0.501676</td>\n",
       "      <td>0.306274</td>\n",
       "      <td>0.190134</td>\n",
       "      <td>0.246648</td>\n",
       "      <td>0.256944</td>\n",
       "      <td>-0.651354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>201646027</td>\n",
       "      <td>2016</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>5069.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176</td>\n",
       "      <td>178</td>\n",
       "      <td>74</td>\n",
       "      <td>140</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>248</td>\n",
       "      <td>192</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7010</td>\n",
       "      <td>6871</td>\n",
       "      <td>13881</td>\n",
       "      <td>6359</td>\n",
       "      <td>6216</td>\n",
       "      <td>3763</td>\n",
       "      <td>1803</td>\n",
       "      <td>1960</td>\n",
       "      <td>5559</td>\n",
       "      <td>2824</td>\n",
       "      <td>2735</td>\n",
       "      <td>2427</td>\n",
       "      <td>1212</td>\n",
       "      <td>1215</td>\n",
       "      <td>2132</td>\n",
       "      <td>1032</td>\n",
       "      <td>1100</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.010086</td>\n",
       "      <td>0.013256</td>\n",
       "      <td>0.013256</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.458108</td>\n",
       "      <td>0.447806</td>\n",
       "      <td>0.505007</td>\n",
       "      <td>0.494993</td>\n",
       "      <td>0.271090</td>\n",
       "      <td>0.400475</td>\n",
       "      <td>0.174843</td>\n",
       "      <td>0.153591</td>\n",
       "      <td>0.098442</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>957 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      YEAR_FIPS  YEAR  REP_VOTES  DEM_VOTES  COUNTY_TOTALVOTES  \\\n",
       "3645  201616015  2016     2673.0      777.0             3814.0   \n",
       "5186  201639113  2016   123909.0   122016.0           258301.0   \n",
       "370    20164019  2016   167428.0   224661.0           421640.0   \n",
       "4726  201630083  2016     3908.0      671.0             4871.0   \n",
       "3548  201613149  2016     3370.0      743.0             4223.0   \n",
       "...         ...   ...        ...        ...                ...   \n",
       "352    20161125  2016    47723.0    31762.0            82700.0   \n",
       "6051  201653025  2016    18518.0     7810.0            28346.0   \n",
       "497    20166095  2016    51920.0   102360.0           166113.0   \n",
       "3673  201616071  2016     1531.0      184.0             2068.0   \n",
       "5461  201646027  2016     2109.0     2608.0             5069.0   \n",
       "\n",
       "      HOUSE_WINNING_BINARY  SENATE_WINNING_BINARY  UNEMPLOYMENT_RATE  \\\n",
       "3645                     1                      1                5.3   \n",
       "5186                     1                      1                5.0   \n",
       "370                      1                      1                4.9   \n",
       "4726                     1                     -1                5.0   \n",
       "3548                     1                      1                5.9   \n",
       "...                    ...                    ...                ...   \n",
       "352                      1                      1                5.6   \n",
       "6051                     0                      0                7.2   \n",
       "497                      0                      0                5.5   \n",
       "3673                     1                      1                3.6   \n",
       "5461                     1                      1                3.0   \n",
       "\n",
       "      AVG_WAGE_SALARY  AA_FEMALE  AA_MALE  BA_FEMALE  BA_MALE  H_FEMALE  \\\n",
       "3645          29404.0         19       19         16       19       129   \n",
       "5186              0.0       5929     5088      60343    52438      6748   \n",
       "370           44683.0      17216    14749      18804    22279    185550   \n",
       "4726              0.0         29       19         18       34       255   \n",
       "3548          48823.0         28       35        620      546       131   \n",
       "...               ...        ...      ...        ...      ...       ...   \n",
       "352           42119.0       1595     1543      34088    28834      3137   \n",
       "6051              0.0        507      464        716      920     18009   \n",
       "497           56189.0      35922    30384      31926    32195     53060   \n",
       "3673          80154.0         17        7          5        7        93   \n",
       "5461              0.0        176      178         74      140       184   \n",
       "\n",
       "      H_MALE  IA_FEMALE  IA_MALE  NA_FEMALE  NA_MALE  TOT_FEMALE  TOT_MALE  \\\n",
       "3645     118         49       38         16        1        3274      3506   \n",
       "5186    7158        664      738        153      121      276368    256101   \n",
       "370   178030      21664    20993       1152     1124      509783    494892   \n",
       "4726     326        107      116          3        5        5515      6016   \n",
       "3548     173         26       30          3        1        5821      5798   \n",
       "...      ...        ...      ...        ...      ...         ...       ...   \n",
       "352     3677        321      352         63       59      104944     98153   \n",
       "6051   19365        982      947         72       75       45882     47086   \n",
       "497    55693       2575     2712       2194     2187      215883    213272   \n",
       "3673      77          8       13          1        2        2081      2095   \n",
       "5461     184        248      192          7        2        7010      6871   \n",
       "\n",
       "      TOT_POP  WA_FEMALE  WA_MALE  TOT_POP_LESS19  TOT_MALE_LESS19  \\\n",
       "3645     6780       3100     3364            1378              724   \n",
       "5186   532469     202227   191271          133218            68087   \n",
       "370   1004675     436929   421722          251775           128334   \n",
       "4726    11531       5221     5694            3115             1570   \n",
       "3548    11619       5034     5079            3012             1566   \n",
       "...       ...        ...      ...             ...              ...   \n",
       "352    203097      67727    66265           52854            26519   \n",
       "6051    92968      42504    43659           30625            15413   \n",
       "497    429155     128494   131478          108866            55825   \n",
       "3673     4176       2029     2043            1279              656   \n",
       "5461    13881       6359     6216            3763             1803   \n",
       "\n",
       "      TOT_FEMALE_LESS19  TOT_POP_20to39  TOT_MALE_20to39  TOT_FEMALE_20to39  \\\n",
       "3645                654            1007              510                497   \n",
       "5186              65131          136568            67271              69297   \n",
       "370              123441          274068           140404             133664   \n",
       "4726               1545            3045             1669               1376   \n",
       "3548               1446            2631             1335               1296   \n",
       "...                 ...             ...              ...                ...   \n",
       "352               26335           68277            33743              34534   \n",
       "6051              15212           24484            12768              11716   \n",
       "497               53041          118148            61056              57092   \n",
       "3673                623             794              390                404   \n",
       "5461               1960            5559             2824               2735   \n",
       "\n",
       "      TOT_POP_40to59  TOT_MALE_40to59  TOT_FEMALE_40to59  TOT_POP_Above60  \\\n",
       "3645            2151             1053               1098             2244   \n",
       "5186          140900            68006              72894           121783   \n",
       "370           241237           117731             123506           237595   \n",
       "4726            3156             1659               1497             2215   \n",
       "3548            3374             1676               1698             2602   \n",
       "...              ...              ...                ...              ...   \n",
       "352            47033            22511              24522            34933   \n",
       "6051           21380            10942              10438            16479   \n",
       "497           117520            58095              59425            84621   \n",
       "3673            1030              519                511             1073   \n",
       "5461            2427             1212               1215             2132   \n",
       "\n",
       "      TOT_MALE_Above60  TOT_FEMALE_Above60  AA_FEMALE%  AA_MALE%  BA_FEMALE%  \\\n",
       "3645              1219                1025    0.002802  0.002802    0.002360   \n",
       "5186             52737               69046    0.011135  0.009555    0.113327   \n",
       "370             108423              129172    0.017136  0.014680    0.018717   \n",
       "4726              1118                1097    0.002515  0.001648    0.001561   \n",
       "3548              1221                1381    0.002410  0.003012    0.053361   \n",
       "...                ...                 ...         ...       ...         ...   \n",
       "352              15380               19553    0.007853  0.007597    0.167841   \n",
       "6051              7963                8516    0.005453  0.004991    0.007702   \n",
       "497              38296               46325    0.083704  0.070800    0.074393   \n",
       "3673               530                 543    0.004071  0.001676    0.001197   \n",
       "5461              1032                1100    0.012679  0.012823    0.005331   \n",
       "\n",
       "      BA_MALE%  H_FEMALE%   H_MALE%  IA_FEMALE%  IA_MALE%  NA_FEMALE%  \\\n",
       "3645  0.002802   0.019027  0.017404    0.007227  0.005605    0.002360   \n",
       "5186  0.098481   0.012673  0.013443    0.001247  0.001386    0.000287   \n",
       "370   0.022175   0.184687  0.177202    0.021563  0.020895    0.001147   \n",
       "4726  0.002949   0.022114  0.028272    0.009279  0.010060    0.000260   \n",
       "3548  0.046992   0.011275  0.014889    0.002238  0.002582    0.000258   \n",
       "...        ...        ...       ...         ...       ...         ...   \n",
       "352   0.141972   0.015446  0.018105    0.001581  0.001733    0.000310   \n",
       "6051  0.009896   0.193712  0.208297    0.010563  0.010186    0.000774   \n",
       "497   0.075020   0.123638  0.129774    0.006000  0.006319    0.005112   \n",
       "3673  0.001676   0.022270  0.018439    0.001916  0.003113    0.000239   \n",
       "5461  0.010086   0.013256  0.013256    0.017866  0.013832    0.000504   \n",
       "\n",
       "      NA_MALE%  WA_FEMALE%  WA_MALE%  TOT_FEMALE%  TOT_MALE%  TOT_POP_LESS19%  \\\n",
       "3645  0.000147    0.457227  0.496165     0.482891   0.517109         0.203245   \n",
       "5186  0.000227    0.379791  0.359215     0.519031   0.480969         0.250189   \n",
       "370   0.001119    0.434896  0.419760     0.507411   0.492589         0.250603   \n",
       "4726  0.000434    0.452779  0.493799     0.478276   0.521724         0.270141   \n",
       "3548  0.000086    0.433256  0.437129     0.500990   0.499010         0.259231   \n",
       "...        ...         ...       ...          ...        ...              ...   \n",
       "352   0.000291    0.333471  0.326273     0.516719   0.483281         0.260240   \n",
       "6051  0.000807    0.457190  0.469613     0.493525   0.506475         0.329414   \n",
       "497   0.005096    0.299412  0.306365     0.503042   0.496958         0.253675   \n",
       "3673  0.000479    0.485872  0.489224     0.498324   0.501676         0.306274   \n",
       "5461  0.000144    0.458108  0.447806     0.505007   0.494993         0.271090   \n",
       "\n",
       "      TOT_POP_20to39%  TOT_POP_40to59%  TOT_POP_Above60%  MARGIN_VICTORY  \\\n",
       "3645         0.148525         0.317257          0.330973       -0.497116   \n",
       "5186         0.256481         0.264616          0.228714       -0.007329   \n",
       "370          0.272793         0.240114          0.236489        0.135739   \n",
       "4726         0.264071         0.273697          0.192091       -0.664545   \n",
       "3548         0.226439         0.290386          0.223944       -0.622070   \n",
       "...               ...              ...               ...             ...   \n",
       "352          0.336179         0.231579          0.172002       -0.192999   \n",
       "6051         0.263359         0.229972          0.177255       -0.377761   \n",
       "497          0.275304         0.273840          0.197181        0.303649   \n",
       "3673         0.190134         0.246648          0.256944       -0.651354   \n",
       "5461         0.400475         0.174843          0.153591        0.098442   \n",
       "\n",
       "      TRAIN  \n",
       "3645      0  \n",
       "5186      0  \n",
       "370       1  \n",
       "4726      0  \n",
       "3548      0  \n",
       "...     ...  \n",
       "352       0  \n",
       "6051      0  \n",
       "497       1  \n",
       "3673      0  \n",
       "5461      0  \n",
       "\n",
       "[957 rows x 56 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.loc[X_test['YEAR'] == year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment#1: 93.208%\n"
     ]
    }
   ],
   "source": [
    "print(\"Experiment#1: {:.3f}%\".format( accuracy_score(y_test, predictions) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.63      0.75       158\n",
      "           1       0.93      0.99      0.96       799\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       957\n",
      "   macro avg       0.94      0.81      0.86       957\n",
      "weighted avg       0.93      0.93      0.93       957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99,  59],\n",
       "       [  6, 793]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - Balance training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/combined_jun22_train.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['ID', 'Unnamed: 0', 'STATE_FIPS', 'COUNTY_FIPS', 'WINNING_CANDIDATE', 'REP_CANDIDATE', 'DEM_CANDIDATE', 'WINNING_PARTY', 'COUNTY', 'STATE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: (957, 56)\n",
      "y_test: (957, 1)\n",
      "X_train: (433, 56)\n",
      "y_train: (433, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:33: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "### retest with Training=1 data.. \n",
    "X_train, X_test, y_train, y_test = train_test_split_by_year_2(data, year, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment#2: 97.910%\n"
     ]
    }
   ],
   "source": [
    "print(\"Experiment#2: {:.3f}%\".format( accuracy_score(y_test, predictions) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       158\n",
      "           1       1.00      0.97      0.99       799\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       957\n",
      "   macro avg       0.94      0.99      0.96       957\n",
      "weighted avg       0.98      0.98      0.98       957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[158,   0],\n",
       "       [ 20, 779]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 - Expr2 + remove demographics absolute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/combined_jun22_train.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['ID', 'Unnamed: 0', 'STATE_FIPS', 'COUNTY_FIPS', 'WINNING_CANDIDATE', 'REP_CANDIDATE', 'DEM_CANDIDATE', 'WINNING_PARTY', 'COUNTY', 'STATE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['AA_FEMALE', 'AA_MALE', 'BA_FEMALE', 'BA_MALE', 'H_FEMALE', 'H_MALE', 'IA_FEMALE', 'IA_MALE', 'NA_FEMALE', 'NA_MALE' , 'TOT_FEMALE', 'TOT_MALE', 'TOT_POP', 'WA_FEMALE', 'WA_MALE', 'TOT_POP_LESS19', 'TOT_MALE_LESS19', 'TOT_FEMALE_LESS19', 'TOT_POP_20to39', 'TOT_MALE_20to39', 'TOT_FEMALE_20to39', 'TOT_POP_40to59', 'TOT_MALE_40to59', 'TOT_FEMALE_40to59', 'TOT_POP_Above60', 'TOT_MALE_Above60', 'TOT_FEMALE_Above60'] , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: (957, 29)\n",
      "y_test: (957, 1)\n",
      "X_train: (433, 29)\n",
      "y_train: (433, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:33: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_by_year_2(data, year, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment#3: 98.746%\n"
     ]
    }
   ],
   "source": [
    "print(\"Experiment#3: {:.3f}%\".format( accuracy_score(y_test, predictions) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       158\n",
      "           1       1.00      0.98      0.99       799\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       957\n",
      "   macro avg       0.96      0.99      0.98       957\n",
      "weighted avg       0.99      0.99      0.99       957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4 - use significant columns only to build the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/combined_jun22_train.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['ID', 'Unnamed: 0', 'STATE_FIPS', 'COUNTY_FIPS', 'WINNING_CANDIDATE', 'REP_CANDIDATE', 'DEM_CANDIDATE', 'WINNING_PARTY', 'COUNTY', 'STATE'], axis=1, inplace=True)\n",
    "data.drop(['AA_FEMALE', 'AA_MALE', 'BA_FEMALE', 'BA_MALE', 'H_FEMALE', 'H_MALE', 'IA_FEMALE', 'IA_MALE', 'NA_FEMALE', 'NA_MALE' , 'TOT_FEMALE', 'TOT_MALE', 'TOT_POP', 'WA_FEMALE', 'WA_MALE', 'TOT_POP_LESS19', 'TOT_MALE_LESS19', 'TOT_FEMALE_LESS19', 'TOT_POP_20to39', 'TOT_MALE_20to39', 'TOT_FEMALE_20to39', 'TOT_POP_40to59', 'TOT_MALE_40to59', 'TOT_FEMALE_40to59', 'TOT_POP_Above60', 'TOT_MALE_Above60', 'TOT_FEMALE_Above60'] , axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: (957, 29)\n",
      "y_test: (957, 1)\n",
      "X_train: (433, 29)\n",
      "y_train: (433, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:33: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_by_year_2(data, year, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR_FIPS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>REP_VOTES</th>\n",
       "      <th>DEM_VOTES</th>\n",
       "      <th>COUNTY_TOTALVOTES</th>\n",
       "      <th>HOUSE_WINNING_BINARY</th>\n",
       "      <th>SENATE_WINNING_BINARY</th>\n",
       "      <th>UNEMPLOYMENT_RATE</th>\n",
       "      <th>AVG_WAGE_SALARY</th>\n",
       "      <th>AA_FEMALE%</th>\n",
       "      <th>AA_MALE%</th>\n",
       "      <th>BA_FEMALE%</th>\n",
       "      <th>BA_MALE%</th>\n",
       "      <th>H_FEMALE%</th>\n",
       "      <th>H_MALE%</th>\n",
       "      <th>IA_FEMALE%</th>\n",
       "      <th>IA_MALE%</th>\n",
       "      <th>NA_FEMALE%</th>\n",
       "      <th>NA_MALE%</th>\n",
       "      <th>WA_FEMALE%</th>\n",
       "      <th>WA_MALE%</th>\n",
       "      <th>TOT_FEMALE%</th>\n",
       "      <th>TOT_MALE%</th>\n",
       "      <th>TOT_POP_LESS19%</th>\n",
       "      <th>TOT_POP_20to39%</th>\n",
       "      <th>TOT_POP_40to59%</th>\n",
       "      <th>TOT_POP_Above60%</th>\n",
       "      <th>MARGIN_VICTORY</th>\n",
       "      <th>TRAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20125017</td>\n",
       "      <td>2012</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>2649.0</td>\n",
       "      <td>4361.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>30300.0</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.285254</td>\n",
       "      <td>0.260678</td>\n",
       "      <td>0.020763</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.215085</td>\n",
       "      <td>0.224322</td>\n",
       "      <td>0.507881</td>\n",
       "      <td>0.492119</td>\n",
       "      <td>0.254407</td>\n",
       "      <td>0.227542</td>\n",
       "      <td>0.273390</td>\n",
       "      <td>0.244661</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20045047</td>\n",
       "      <td>2004</td>\n",
       "      <td>4181.0</td>\n",
       "      <td>3008.0</td>\n",
       "      <td>7289.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>0.010663</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.487467</td>\n",
       "      <td>0.479038</td>\n",
       "      <td>0.503433</td>\n",
       "      <td>0.496567</td>\n",
       "      <td>0.281137</td>\n",
       "      <td>0.239770</td>\n",
       "      <td>0.267515</td>\n",
       "      <td>0.211578</td>\n",
       "      <td>-0.160927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200848395</td>\n",
       "      <td>2008</td>\n",
       "      <td>3980.0</td>\n",
       "      <td>2675.0</td>\n",
       "      <td>6710.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.121721</td>\n",
       "      <td>0.105222</td>\n",
       "      <td>0.082497</td>\n",
       "      <td>0.083887</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.376526</td>\n",
       "      <td>0.373021</td>\n",
       "      <td>0.509670</td>\n",
       "      <td>0.490330</td>\n",
       "      <td>0.288952</td>\n",
       "      <td>0.214614</td>\n",
       "      <td>0.271365</td>\n",
       "      <td>0.225070</td>\n",
       "      <td>-0.194486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200426125</td>\n",
       "      <td>2004</td>\n",
       "      <td>316633.0</td>\n",
       "      <td>319387.0</td>\n",
       "      <td>641977.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>48100.0</td>\n",
       "      <td>0.024143</td>\n",
       "      <td>0.024681</td>\n",
       "      <td>0.060394</td>\n",
       "      <td>0.051156</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.416991</td>\n",
       "      <td>0.404963</td>\n",
       "      <td>0.510614</td>\n",
       "      <td>0.489386</td>\n",
       "      <td>0.271320</td>\n",
       "      <td>0.266428</td>\n",
       "      <td>0.305248</td>\n",
       "      <td>0.157004</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200828149</td>\n",
       "      <td>2008</td>\n",
       "      <td>11152.0</td>\n",
       "      <td>10489.0</td>\n",
       "      <td>21709.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>0.249212</td>\n",
       "      <td>0.212253</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.267417</td>\n",
       "      <td>0.253422</td>\n",
       "      <td>0.525334</td>\n",
       "      <td>0.474666</td>\n",
       "      <td>0.295202</td>\n",
       "      <td>0.246751</td>\n",
       "      <td>0.287045</td>\n",
       "      <td>0.171003</td>\n",
       "      <td>-0.030540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>20085105</td>\n",
       "      <td>2008</td>\n",
       "      <td>2743.0</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>4279.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.008670</td>\n",
       "      <td>0.008479</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481517</td>\n",
       "      <td>0.478659</td>\n",
       "      <td>0.502096</td>\n",
       "      <td>0.497904</td>\n",
       "      <td>0.260290</td>\n",
       "      <td>0.227325</td>\n",
       "      <td>0.290682</td>\n",
       "      <td>0.221704</td>\n",
       "      <td>-0.325076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>20046081</td>\n",
       "      <td>2004</td>\n",
       "      <td>83315.0</td>\n",
       "      <td>197922.0</td>\n",
       "      <td>284077.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>62147.0</td>\n",
       "      <td>0.118791</td>\n",
       "      <td>0.107160</td>\n",
       "      <td>0.016958</td>\n",
       "      <td>0.017430</td>\n",
       "      <td>0.110334</td>\n",
       "      <td>0.114978</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>0.344353</td>\n",
       "      <td>0.342763</td>\n",
       "      <td>0.506701</td>\n",
       "      <td>0.493299</td>\n",
       "      <td>0.247110</td>\n",
       "      <td>0.289754</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>0.170159</td>\n",
       "      <td>0.403436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>20006025</td>\n",
       "      <td>2000</td>\n",
       "      <td>12524.0</td>\n",
       "      <td>15489.0</td>\n",
       "      <td>28937.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>24908.0</td>\n",
       "      <td>0.011536</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>0.010869</td>\n",
       "      <td>0.032332</td>\n",
       "      <td>0.359043</td>\n",
       "      <td>0.363321</td>\n",
       "      <td>0.011297</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.439108</td>\n",
       "      <td>0.460937</td>\n",
       "      <td>0.477869</td>\n",
       "      <td>0.522131</td>\n",
       "      <td>0.345757</td>\n",
       "      <td>0.295593</td>\n",
       "      <td>0.225863</td>\n",
       "      <td>0.132786</td>\n",
       "      <td>0.102464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>200026159</td>\n",
       "      <td>2000</td>\n",
       "      <td>14792.0</td>\n",
       "      <td>13796.0</td>\n",
       "      <td>29482.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.028004</td>\n",
       "      <td>0.025630</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.461352</td>\n",
       "      <td>0.456249</td>\n",
       "      <td>0.503810</td>\n",
       "      <td>0.496190</td>\n",
       "      <td>0.308871</td>\n",
       "      <td>0.246698</td>\n",
       "      <td>0.280644</td>\n",
       "      <td>0.163788</td>\n",
       "      <td>-0.033783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>201221177</td>\n",
       "      <td>2012</td>\n",
       "      <td>7762.0</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>12739.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>38971.0</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.018953</td>\n",
       "      <td>0.029282</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.468918</td>\n",
       "      <td>0.469739</td>\n",
       "      <td>0.494219</td>\n",
       "      <td>0.505781</td>\n",
       "      <td>0.243035</td>\n",
       "      <td>0.247615</td>\n",
       "      <td>0.282235</td>\n",
       "      <td>0.227115</td>\n",
       "      <td>-0.234791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR_FIPS  YEAR  REP_VOTES  DEM_VOTES  COUNTY_TOTALVOTES  \\\n",
       "0     20125017  2012     1670.0     2649.0             4361.0   \n",
       "1     20045047  2004     4181.0     3008.0             7289.0   \n",
       "2    200848395  2008     3980.0     2675.0             6710.0   \n",
       "3    200426125  2004   316633.0   319387.0           641977.0   \n",
       "4    200828149  2008    11152.0    10489.0            21709.0   \n",
       "..         ...   ...        ...        ...                ...   \n",
       "428   20085105  2008     2743.0     1352.0             4279.0   \n",
       "429   20046081  2004    83315.0   197922.0           284077.0   \n",
       "430   20006025  2000    12524.0    15489.0            28937.0   \n",
       "431  200026159  2000    14792.0    13796.0            29482.0   \n",
       "432  201221177  2012     7762.0     4771.0            12739.0   \n",
       "\n",
       "     HOUSE_WINNING_BINARY  SENATE_WINNING_BINARY  UNEMPLOYMENT_RATE  \\\n",
       "0                       1                     -1               11.4   \n",
       "1                       0                      0                4.8   \n",
       "2                       1                      1                4.9   \n",
       "3                       1                     -1                5.7   \n",
       "4                       0                      1                6.3   \n",
       "..                    ...                    ...                ...   \n",
       "428                     1                      0                5.6   \n",
       "429                     0                      0                4.8   \n",
       "430                     1                      0               17.5   \n",
       "431                     1                      0                4.1   \n",
       "432                     0                     -1                9.8   \n",
       "\n",
       "     AVG_WAGE_SALARY  AA_FEMALE%  AA_MALE%  BA_FEMALE%  BA_MALE%  H_FEMALE%  \\\n",
       "0            30300.0    0.002627  0.002373    0.285254  0.260678   0.020763   \n",
       "1                0.0    0.002568  0.002177    0.002345  0.005080   0.008597   \n",
       "2                0.0    0.002418  0.002659    0.121721  0.105222   0.082497   \n",
       "3            48100.0    0.024143  0.024681    0.060394  0.051156   0.013688   \n",
       "4                0.0    0.004149  0.003722    0.249212  0.212253   0.008034   \n",
       "..               ...         ...       ...         ...       ...        ...   \n",
       "428              0.0    0.000953  0.000762    0.009623  0.008670   0.008479   \n",
       "429          62147.0    0.118791  0.107160    0.016958  0.017430   0.110334   \n",
       "430          24908.0    0.011536  0.013054    0.010869  0.032332   0.359043   \n",
       "431              0.0    0.001784  0.001430    0.028004  0.025630   0.033579   \n",
       "432          38971.0    0.000821  0.000663    0.018953  0.029282   0.005275   \n",
       "\n",
       "      H_MALE%  IA_FEMALE%  IA_MALE%  NA_FEMALE%  NA_MALE%  WA_FEMALE%  \\\n",
       "0    0.025424    0.001356  0.001780    0.000254  0.000085    0.215085   \n",
       "1    0.010663    0.004968  0.004354    0.000391  0.000391    0.487467   \n",
       "2    0.083887    0.003808  0.004170    0.000060  0.000121    0.376526   \n",
       "3    0.014545    0.001467  0.001448    0.000150  0.000142    0.416991   \n",
       "4    0.010109    0.001322  0.001546    0.000020  0.000102    0.267417   \n",
       "..        ...         ...       ...         ...       ...         ...   \n",
       "428  0.010766    0.003430  0.003049    0.000095  0.000000    0.481517   \n",
       "429  0.114978    0.003011  0.003278    0.007585  0.007422    0.344353   \n",
       "430  0.363321    0.011297  0.010258    0.000660  0.000773    0.439108   \n",
       "431  0.040229    0.004958  0.004722    0.000079  0.000052    0.461352   \n",
       "432  0.006697    0.000663  0.000790    0.000063  0.000095    0.468918   \n",
       "\n",
       "     WA_MALE%  TOT_FEMALE%  TOT_MALE%  TOT_POP_LESS19%  TOT_POP_20to39%  \\\n",
       "0    0.224322     0.507881   0.492119         0.254407         0.227542   \n",
       "1    0.479038     0.503433   0.496567         0.281137         0.239770   \n",
       "2    0.373021     0.509670   0.490330         0.288952         0.214614   \n",
       "3    0.404963     0.510614   0.489386         0.271320         0.266428   \n",
       "4    0.253422     0.525334   0.474666         0.295202         0.246751   \n",
       "..        ...          ...        ...              ...              ...   \n",
       "428  0.478659     0.502096   0.497904         0.260290         0.227325   \n",
       "429  0.342763     0.506701   0.493299         0.247110         0.289754   \n",
       "430  0.460937     0.477869   0.522131         0.345757         0.295593   \n",
       "431  0.456249     0.503810   0.496190         0.308871         0.246698   \n",
       "432  0.469739     0.494219   0.505781         0.243035         0.247615   \n",
       "\n",
       "     TOT_POP_40to59%  TOT_POP_Above60%  MARGIN_VICTORY  TRAIN  \n",
       "0           0.273390          0.244661        0.224490      1  \n",
       "1           0.267515          0.211578       -0.160927      1  \n",
       "2           0.271365          0.225070       -0.194486      1  \n",
       "3           0.305248          0.157004        0.004290      1  \n",
       "4           0.287045          0.171003       -0.030540      1  \n",
       "..               ...               ...             ...    ...  \n",
       "428         0.290682          0.221704       -0.325076      1  \n",
       "429         0.292977          0.170159        0.403436      1  \n",
       "430         0.225863          0.132786        0.102464      1  \n",
       "431         0.280644          0.163788       -0.033783      1  \n",
       "432         0.282235          0.227115       -0.234791      1  \n",
       "\n",
       "[433 rows x 29 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['YEAR',\n",
       " 'REP_VOTES',\n",
       " 'DEM_VOTES',\n",
       " 'COUNTY_TOTALVOTES',\n",
       " 'HOUSE_WINNING_BINARY',\n",
       " 'SENATE_WINNING_BINARY',\n",
       " 'UNEMPLOYMENT_RATE',\n",
       " 'AVG_WAGE_SALARY',\n",
       " 'BA_FEMALE%',\n",
       " 'BA_MALE%',\n",
       " 'H_MALE%',\n",
       " 'IA_FEMALE%',\n",
       " 'WA_FEMALE%',\n",
       " 'WA_MALE%',\n",
       " 'TOT_FEMALE%',\n",
       " 'TOT_MALE%',\n",
       " 'TOT_POP_LESS19%',\n",
       " 'TOT_POP_20to39%',\n",
       " 'TOT_POP_40to59%',\n",
       " 'MARGIN_VICTORY']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "rfe = RFE(model, 20)\n",
    "rfe = rfe.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "values = rfe.support_.tolist()\n",
    "\n",
    "cols = []\n",
    "\n",
    "for val, column in zip(values, X_train.columns):\n",
    "    if val == True:\n",
    "        cols.append(column)\n",
    "        \n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: (957, 20)\n",
      "y_test: (957, 1)\n",
      "X_train: (433, 20)\n",
      "y_train: (433, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:33: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "#split by: train=1; significant columns\n",
    "X_train, X_test, y_train, y_test = train_test_split_by_year_2(data, year, True, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LogisticRegression(C=0.0001, solver='lbfgs', dual=False, max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment#4: 98.746%\n"
     ]
    }
   ],
   "source": [
    "print(\"Experiment#4: {:.3f}%\".format(accuracy_score(y_test, predictions) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       158\n",
      "           1       1.00      0.98      0.99       799\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       957\n",
      "   macro avg       0.96      0.99      0.98       957\n",
      "weighted avg       0.99      0.99      0.99       957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[158,   0],\n",
       "       [ 12, 787]])"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best Model Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:1297: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:1297: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:1297: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:1297: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:1297: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  liblinear: 0.850\n",
      "  newton-cg: 0.998\n",
      "  lbfgs: 0.857\n",
      "  sag: 0.798\n",
      "  saga: 0.796\n"
     ]
    }
   ],
   "source": [
    "#1) Find the best Solver.\n",
    "solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "params = dict(solver=solver_list)\n",
    "log_reg = LogisticRegression(C=1, n_jobs=-1, random_state=34)\n",
    "clf = GridSearchCV(log_reg, params, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "\n",
    "for score, solver in zip(scores, solver_list):\n",
    "    print(f\"  {solver}: {score:.3f}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find the best properties for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "logModel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "#     'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(logModel, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 42.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 124.6min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 355.6min finished\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#### warning: this will take up to 6 horus :) ##\n",
    "best_clf = clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=1000,\n",
       "          multi_class='warn', n_jobs=None, penalty='l1', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.983\n"
     ]
    }
   ],
   "source": [
    "print (f'Accuracy: {best_clf.score(X,y):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.491%\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.3f}%\".format( accuracy_score(y_test, predictions) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identify significant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.0001, solver='lbfgs', dual=False, max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False  True  True False  True  True False  True\n",
      " False False False  True  True  True False False  True  True  True  True\n",
      "  True  True False  True  True False  True  True False False False False\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "#Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "rfe = RFE(model, 20)\n",
    "rfe = rfe.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(rfe.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STATE_FIPS',\n",
       " 'COUNTY_FIPS',\n",
       " 'REP_VOTES',\n",
       " 'DEM_VOTES',\n",
       " 'WINNING_PARTY_BINARY',\n",
       " 'AA_MALE',\n",
       " 'BA_FEMALE',\n",
       " 'BA_MALE',\n",
       " 'IA_FEMALE',\n",
       " 'IA_MALE',\n",
       " 'NA_FEMALE',\n",
       " 'NA_MALE',\n",
       " 'TOT_FEMALE',\n",
       " 'TOT_MALE',\n",
       " 'WA_FEMALE',\n",
       " 'WA_MALE',\n",
       " 'TOT_MALE_LESS19',\n",
       " 'TOT_FEMALE_LESS19',\n",
       " 'TOT_MALE_40to59',\n",
       " 'TOT_FEMALE_40to59']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = rfe.support_.tolist()\n",
    "\n",
    "cols = []\n",
    "\n",
    "for val, column in zip(values, X_train.columns):\n",
    "    if val == True:\n",
    "        cols.append(column)\n",
    "        \n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=5000,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9752729608220938"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: (3114, 19)\n",
      "y_test: (3114,)\n",
      "X_train: (11569, 19)\n",
      "y_train: (11569,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:32: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9996788696210661"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after\n",
    "X_train, X_test, y_train, y_test = train_test_split_by_year(data, 2016, True, cols)\n",
    "\n",
    "model = LogisticRegression(C=0.0001, solver='lbfgs', dual=False, max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAD4CAYAAABi3BrkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAASi0lEQVR4nO3de5zXVZ3H8ddnBnXVIGYQEbl5wwzzkbneyszr4nWDNEnTJMLwAqatm5IaImYP3V1bxdREHcVWYdldUyqSiDS1UgHzhpekDIW4KV4BReDsH/PFfioz8xuY4TeceT19fB/z+53f93K+Drw553u+5/uLlBKSlIOqSldAklqKgSYpGwaapGwYaJKyYaBJykaH1j7Aw4sfchh1E7JHbb9KV0HrYesOtbEh2295yJiy/56uuG/UBh2rNdlCk5SNVm+hSdoERJttdDWLgSYJqqsrXYMWYaBJsoUmKSORx+V0A00SVNlCk5QLu5ySsmGXU1I2qg00SbmwhSYpG15Dk5QNW2iSsuFtG5KyUeXUJ0m58BqapGzY5ZSUDQcFJGXDLqekbBhokrLhAx4lZcMWmqRsOCggKRvetiEpG3Y5JWXDqU+SsmGXU1I2HBSQlA2voUnKRRhoknKRSZ4ZaJKgujqPRDPQJNnllJSPTPLMQJOUTwstj5tPJG2QiCh7KWNfvSLivoh4JiJmR8Q5RXltREyLiBeKnzVFeUTE2IiYExFPRsReJfsaXKz/QkQMburYBpokIspfyrAKOC+l1A/YHxgeEf2AkcD0lFJfYHrxHuAooG+xDANuqK9T1AKXAPsB+wKXrA3BhhhokqiqjrKXpqSUFqSUHitevwU8C/QABgDji9XGAwOL1wOA21O9h4HOEdEdOAKYllJamlJ6DZgGHNnoeTT/1CXlpjldzogYFhEzS5Zhjex3B+AzwCNAt5TSguKjhUC34nUP4OWSzeYVZQ2VN8hBAUnNGuVMKY0DxjW9z/gY8H/AuSmlN0uvv6WUUkSk5te0cbbQJFEVUfZSjojYjPowuyOldFdRvKjoSlL8XFyUzwd6lWzesyhrqLzh8yirdpKy1sKjnAHcAjybUvphyUeTgbUjlYOBe0rKTy1GO/cH3ii6plOB/hFRUwwG9C/KGmSXUxJVLfs8tAOArwFPRcTjRdmFwBXApIgYCswFBhWfTQGOBuYAy4EhACmlpRFxGTCjWG9MSmlpYwc20CS16EyBlNJDQEN7PGwd6ydgeAP7qgPqyj22gSaJ8Im1knKRycwnA01SPnM5DTRJttAk5aOqKo87uAw0Sbl8i52BJslRznZh2VvLqbvyNua/OB8iOG3k19nlU7sA8MuJU5l43SR+9LOr6di5I8vfXs6Nl93Mq4teZfXqNRx14hF84ZjPV/gM2rfVq1dzyqAhdO3WlbHXX0VKievG3sivp/6GquoqTvjKcZx0yqCmd9QOeA2tHbhj7AT22O9TnP39s1j13irefWclAK8uWsrTj86mS7fa99edftd9bL9Dd7595bd487W3GHnyhXyu//502Mz/xZUy4SeT2HGnHXh72TIAJt/9CxYtXMRdP59IVVUVS19t9KbzdiWXUc4mrwRGxG4RcUHxRMmxxetPbozKVdLyt5fz/BN/4qBjDwSgw2Yd2LrjVgDcee1EvnLWCR/8QxDwzvJ3SCnx7op32LrTx6iqzuNC66Zo0cLFPPjA7xh4/BffL/vfiXfxzTO+8f4F8NoutQ1t3u608AMeK6bR5kNEXACcBEwEHi2KewITImJiSumKVq5fxSxZ8AodO3fk5h/U8dKfX2aHXXfglHNOYvbMZ6jp2pneu/T6wPqHH38oV4+8lnMGnsc7K97hrNGnZzNytCn6jyuu5pzzRrB82fL3y+a9PJ9f3Tud+6b/lpqazpx/4b/Qu0+vRvbSfuTyZ7WpsxgK7JNSuiKl9F/FcgX1j8Md2tBGpQ+Au/v2yS1Z341mzeo1zP3TXA4deAiX1Y1miy0356d19/Czn/yC44YO/Mj6Tz8ym9679Oaau6/isrpL+MnVd7Ji2YoK1FwP3P8QtbU19Nt9tw+Ur1z5HltssTl3TLqVL315AKMvvrxCNWx72kULDVgDbE/9zPhS3YvP1qn0AXAPL36oxR/itjHUdK2htmsNO+++EwD7HLw3d9fdw5IFr/C9IaMBWLrkNUYNHcMl4y7mwSkPccwpRxMRdOvZja7dt+Fvcxewc7+dKngW7dMTf3yS397/IA89+HtWvruSZcuWcdEFo+m2XVcOPfxgAA49/CAuvfj7la1oG9JeRjnPBaZHxAv8/VG4vYFdgBGtWbFK69zl49RuW8uClxbSvfd2PDPrWfrs2ocLrvnO++ucd8L5jL7pe3Ts3JHabl14ZtazfOLTu/LG0jdY8NJCtt2+awXPoP06+9tncfa3zwJg5qOPcfttd3D5laMZ+8PrmfHoLHr03J5ZM/5I7z69K1zTtqOtt7zK1WigpZTujYhdqe9irn2W93xgRkppdWtXrtJOOfer/HjMOFa9t5ptt9+G0y78RoPrDvj6sdz0gzouGjyKlBKDzvgyHTt33Ii1VVOGnPY1LrpgNHfePpEtt9qKUWO+W+kqtRnlPom2rYv6RxG1nk21y9le7VHbr9JV0HrYukPtBiXSXtc+UPbf08fO/kKbTT9vkpLUbq6hSWoHcrmx1kCT1D4GBSS1D7bQJGXDa2iSstHCX2NXMQaapGzuQzPQJDkoICkfXkOTlA1HOSVlI5M8M9Akkc3TlQ00SbbQJOXDa2iSsmGgScpGJndtGGiSHBSQlJFMepwGmiSvoUnKSC5Tn/LoOEvaIC35RcMRURcRiyPi6ZKy0RExPyIeL5ajSz77bkTMiYjnI+KIkvIji7I5ETGynPMw0CQREWUvZbgNOHId5f+ZUtqzWKYUx+0HnAjsXmxzfURUR0Q1cB1wFNAPOKlYt1F2OSVR3YJdzpTSAxGxQ5mrDwAmppTeBV6MiDnUfw8wwJyU0l8AImJise4zje3MFpokIlIzlhgWETNLlmFlHmZERDxZdElrirIewMsl68wryhoqb5SBJqlZ19BSSuNSSnuXLOPKOMQNwM7AnsAC4KrWOA+7nJKoirK/OH29pJQWrX0dETcBPy/ezgd6lazasyijkfIG2UKTRDRjWa/9R3QvefslYO0I6GTgxIjYIiJ2BPoCjwIzgL4RsWNEbE79wMHkpo5jC00S1VUt10KLiAnAwcA2ETEPuAQ4OCL2BBLwV+B0gJTS7IiYRP3F/lXA8JTS6mI/I4CpQDVQl1Ka3dSxDTRJLTr1KaV00jqKb2lk/cuBy9dRPgWY0pxjG2iSWv0a2sZioEla72tjbY2BJskWmqR8ZPKwDQNNElTbQpOUizDQJOUik8ehGWiSbKFJyogtNEnZCGyhScpES87lrCQDTZL3oUnKhzMFJGUjkwaagSbJLqekjDgoICkbVd62ISkXdjklZcOpT5Ky4dSnMu3ZZY/WPoRaUM3h11S6CloPK+4btUHb20KTlA0f8CgpG7l847iBJskup6R8ZDImYKBJcnK6pIzYQpOUDedySsqGLTRJ2fAamqRs2EKTlA1baJKyYaBJyoZTnyRlw6lPkrKRSwstl/OQtAEiUtlL0/uKuohYHBFPl5TVRsS0iHih+FlTlEdEjI2IORHxZETsVbLN4GL9FyJicDnnYaBJoqoZSxluA478UNlIYHpKqS8wvXgPcBTQt1iGATdAfQAClwD7AfsCl6wNwabOQ1I7VxWp7KUpKaUHgKUfKh4AjC9ejwcGlpTfnuo9DHSOiO7AEcC0lNLSlNJrwDQ+GpIf4TU0Sc26bSMihlHfmlprXEppXBObdUspLSheLwS6Fa97AC+XrDevKGuovFEGmqRmfY1dEV5NBVhj26dopWFVu5ySqCKVvaynRUVXkuLn4qJ8PtCrZL2eRVlD5U2ch6R2L6L8ZT1NBtaOVA4G7ikpP7UY7dwfeKPomk4F+kdETTEY0L8oa5RdTkktOjk9IiYABwPbRMQ86kcrrwAmRcRQYC4wqFh9CnA0MAdYDgwBSCktjYjLgBnFemNSSh8eaPgIA01Si36NXUrppAY+Omwd6yZgeAP7qQPqmnNsA02Sk9Ml5cPnoUnKhpPTJWUjl9sdDDRJVG3A/RhtiYEmiTDQJOUijzgz0CQBkUmkGWiSNmRKU5tioEmiyhaapFw4yikpG5nkmYEmyUEBSRmxhSYpG7bQJGWjOpMmmoEmKZP2mYEmCedySspIHnFmoEnCFpqkjOQRZwaaJBzllJQR70OTlI1MGmgGmqR8Wmi5fNnLRjPqoss4+PNHcNwXT6x0Vdq9nl07ce8PT+WxW89k1q1nMPz4fT/w+Tkn7M+K+0bRpdOWAOzaqwv3/+gbvD71Qs4d9NkPrDv8+H2ZWXcGs249gxHH77fRzqGtiCh/acsMtGYa8KVjuGHcNZWuhoBVq9cw8oZfsdeQGzjorDpOH7APu/XZBqgPu8P22ZmXFr7+/vqvvbWC8669l6sn/eED++m3Q1eGHLMXB555M/sOvZGjPtuXnbav2ajnUmnRjP/aMgOtmf5x773o9PFOla6GgIVL3+bxFxYC8PaKlTz30itsv0397+bfhvfnoht/TenX5y55fTmznv8b761a84H97NZnG2Y8O58V765i9ZrEg0/MZeAXPrmxTqNNqIooe2nLDDRloXe3j7PnLtsx49l5HHvArvztlbd46s+Lytp29otLOGCP3tR22pItt+jAkfv1pWfX9vWPVlUzlrZsvesXEUMa+WxYRMyMiJm33HTb+h5CKsvW/7AZE8acwHeum8qq1Ws4/+QDGXPr/WVv//xLr3DVxN/xs38/mclXnswTcxayes2apjfMSESUvbRlGzLKeSlw67o+SCmNA8YBvLP6jbSudaSW0KG6igljBvHfv36aex58jt133JY+23Xm0ZtPB6BH1078YdwwDjzzZha9tqzB/Yyf8jjjpzwOwKWnHcr8JW9ulPq3HW07qMrVaKBFxJMNfQR0a/nqSM3z4/P/mefnLmHs/zwMwOwXF9PnuKve//y5Cd/igNNv4tU3VzS6n66dt2LJ68vptW0nBhy4GweddUur1rutySPOmm6hdQOOAF77UHkAv2+VGrVxF/zrxcx8dBavv/46/3TIsZw54pscd/yASlerXfrcp3pxcv9P89SfF/HwTcMAuOTm3zD1kTnrXL9bzdb87sZv0nGrLViTEiO+vB+f+fr1vLV8JRMuHURtpy15b/Vqzr3ml7yx7N2NeSoVF9HWr46VJ1JquEcYEbcAt6aUHlrHZ3emlL7a1AHscm5aag73lpRN0Yr7Rm1QI+vxVx8p++/pnl32a7MNukZbaCmloY181mSYSdo0tPX7y8rl1CdJbX8KQJny6DhL2iDRjKWs/UX8NSKeiojHI2JmUVYbEdMi4oXiZ01RHhExNiLmRMSTEbHX+p6HgSaJlo80AA5JKe2ZUtq7eD8SmJ5S6gtML94DHAX0LZZhwA3rexYGmqSNNfVpADC+eD0eGFhSfnuq9zDQOSK6r9d5bEjtJOWi/BZa6UygYhm2jh0m4FcRMavk824ppQXF64X8/V7WHsDLJdvOK8qazUEBSc0a5SydCdSIz6eU5kfEtsC0iHjuQ/tIEdHit3TZQpPU4lfQUkrzi5+LgZ8C+wKL1nYli5+Li9XnA71KNu9ZlDWbgSapRZ/wGBFbR0THta+B/sDTwGRgcLHaYOCe4vVk4NRitHN/4I2Srmmz2OWU1NI31nYDflo8maMDcGdK6d6ImAFMioihwFxgULH+FOBoYA6wHGjwST5NMdAktWigpZT+Anx6HeWvAoetozwBw1vi2AaapDb/nLNyGWiSyOUBQgaapEzizECThE/bkJQRr6FJyoYtNEkZMdAkZSKTHqeBJglsoUnKhtfQJGXDUU5J2bCFJikbBpqkfOSRZwaaJFtokjJioEnKhqOckrJhC01SNvKIMwNNEmQzmdNAk2SXU1I+qgw0SdnII88MNEl2OSVlJJdAq6p0BSSppdhCk+RMAUn5cJRTUj5soUnKRS6DAgaapEzizECThC00STnxGpqkXDjKKSkfttAk5SKPODPQJOGggKSMGGiSspHLXM5IKVW6DpusiBiWUhpX6XqoPP6+8ufjgzbMsEpXQM3i7ytzBpqkbBhokrJhoG0Yr8dsWvx9Zc5BAUnZsIUmKRsGmqRsGGjrISKOjIjnI2JORIysdH3UuIioi4jFEfF0peui1mWgNVNEVAPXAUcB/YCTIqJfZWulJtwGHFnpSqj1GWjNty8wJ6X0l5TSSmAiMKDCdVIjUkoPAEsrXQ+1PgOt+XoAL5e8n1eUSaowA01SNgy05psP9Cp537Mok1RhBlrzzQD6RsSOEbE5cCIwucJ1koSB1mwppVXACGAq8CwwKaU0u7K1UmMiYgLwB+ATETEvIoZWuk5qHU59kpQNW2iSsmGgScqGgSYpGwaapGwYaJKyYaBJyoaBJikb/w8SHchnaOgA+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axes = sns.heatmap(matrix, square=True, annot=True, fmt='d', cbar=True, cmap=plt.cm.GnBu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state=5, county=147,    prediction=1,    expected=0\n",
      "state=8, county=15,    prediction=1,    expected=0\n",
      "state=8, county=111,    prediction=1,    expected=0\n",
      "state=12, county=65,    prediction=1,    expected=0\n",
      "state=13, county=7,    prediction=1,    expected=0\n",
      "state=13, county=239,    prediction=1,    expected=0\n",
      "state=17, county=15,    prediction=1,    expected=0\n",
      "state=17, county=85,    prediction=1,    expected=0\n",
      "state=17, county=155,    prediction=1,    expected=0\n",
      "state=19, county=39,    prediction=1,    expected=0\n",
      "state=19, county=115,    prediction=1,    expected=0\n",
      "state=19, county=131,    prediction=1,    expected=0\n",
      "state=21, county=63,    prediction=1,    expected=0\n",
      "state=24, county=3,    prediction=0,    expected=1\n",
      "state=26, county=159,    prediction=1,    expected=0\n",
      "state=27, county=23,    prediction=1,    expected=0\n",
      "state=27, county=69,    prediction=1,    expected=0\n",
      "state=27, county=73,    prediction=1,    expected=0\n",
      "state=27, county=155,    prediction=1,    expected=0\n",
      "state=28, county=9,    prediction=1,    expected=0\n",
      "state=28, county=55,    prediction=1,    expected=0\n",
      "state=35, county=7,    prediction=1,    expected=0\n",
      "state=35, county=23,    prediction=1,    expected=0\n",
      "state=36, county=15,    prediction=1,    expected=0\n",
      "state=36, county=57,    prediction=1,    expected=0\n",
      "state=37, county=73,    prediction=1,    expected=0\n",
      "state=38, county=81,    prediction=1,    expected=0\n",
      "state=38, county=91,    prediction=1,    expected=0\n",
      "state=45, county=29,    prediction=1,    expected=0\n",
      "state=45, county=65,    prediction=1,    expected=0\n",
      "state=46, county=31,    prediction=1,    expected=0\n",
      "state=46, county=37,    prediction=1,    expected=0\n",
      "state=46, county=91,    prediction=1,    expected=0\n",
      "state=46, county=137,    prediction=1,    expected=0\n",
      "state=48, county=109,    prediction=1,    expected=0\n",
      "state=51, county=29,    prediction=1,    expected=0\n",
      "state=51, county=125,    prediction=1,    expected=0\n",
      "state=51, county=750,    prediction=1,    expected=0\n",
      "state=51, county=840,    prediction=1,    expected=0\n",
      "state=53, county=9,    prediction=1,    expected=0\n",
      "state=55, county=11,    prediction=1,    expected=0\n",
      "state=55, county=41,    prediction=1,    expected=0\n",
      "state=55, county=69,    prediction=1,    expected=0\n",
      "state=55, county=77,    prediction=1,    expected=0\n",
      "state=55, county=91,    prediction=1,    expected=0\n",
      "state=55, county=99,    prediction=1,    expected=0\n",
      "state=55, county=113,    prediction=1,    expected=0\n",
      "total_rows=3114\n",
      "total_wrong_predictions=47\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "wrong_predictions = 0\n",
    "for state, county, prediction, label in zip( X_test.STATE, X_test.COUNTY, predictions, y_test):\n",
    "    if prediction != label:\n",
    "        wrong_predictions +=1\n",
    "        print('state={}, county={},    prediction={},    expected={}'.format(state, county, prediction, label))\n",
    "    counter += 1\n",
    "   \n",
    "print('total_rows={}'.format(counter))\n",
    "print('total_wrong_predictions={}'.format(wrong_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
